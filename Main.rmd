```{r}
library("devtools") ## this needs to be installed and loaded prior to running
### the following:
# install_github("helixcn/seqRFLP")
# install_github("JCSzamosi/aftersl1p@*release")

## load packages:
library("phyloseq")
library("ShortRead") 
library("tidyverse") ## ggplot, dplyr, et c.
library("Polychrome") ## generate randomized discrete colour palettes
library("paletteer") ## generate colour palettes
library("readr") ## read_csv function
library("cluster")
library("data.table")
library("grid")
library("ape")
library("phangorn")
library("phytools")
library("vegan")
library("seqinr")
library("seqRFLP")
library("AfterSl1p")
```

```{r}
otufile <- ##Seqtab file

otu_df <- read.csv(otufile, row.names = 1)

seqs <- rownames(otu_df)

rownames(otu_df) = NULL

taxfile <- ##Taxa file

all(seqs == rownames(tax_df))

rownames(tax_df) = NULL

metfile <- ##Mapfile
map_df <- read.csv(metfile)

map_df$NAME <- gsub('-', '.', as.character(map_df$NAME))

map_df$NAME <- gsub(' ', '.', map_df$NAME)

map_df$NAME <- factor(map_df$NAME,
                      levels = c("EC1", "EC2","EC3",
                                 "EC4", "EC5", "EC6",
                                 "EC7", "EC8", "EC9", "EC10",  "EC11",  "EC12",  "EC13",  "EC14",  "EC15",  "EC16",  "EC17",  "EC18",  "EC19",  "EC20",  "EC21",  "EC22",  "EC23",  "EC24",  "EC25"))

rownames(map_df) <- map_df$NAME

rows <- sort(rownames(map_df)) 
cols <- sort(colnames(otu_df))

colnames(map_df) <- gsub(" ", ".", colnames(map_df))  # Replace spaces with dots
colnames(map_df) <- gsub("\\(|\\)", "", colnames(map_df))  # Remove parentheses
map_df$Weight.mg <- as.numeric(map_df$Weight..g.) # Ensuring weight is numbers
map_df$Wing.Chord.mm <- as.numeric(map_df$Wing.Chord..mm.) # Ensuring wing chord is numbers
map_df$Right.Tarsus.mm <- as.numeric(map_df$Right.Tarsus..mm.) # Ensuring right tarsus is numbers
map_df$X9th.Primary.mm <- as.numeric(map_df$X9th.Primary..mm.) # Ensuring 9th primary is numbers
map_df$Box.Temperature <- as.numeric(map_df$Box.Temperature) # Ensuring box temp is numbers
```

```{r}
colnames(map_df) <- gsub(" ", ".", colnames(map_df))  # Replace spaces with dots
colnames(map_df) <- gsub("\\(|\\)", "", colnames(map_df))  # Remove parentheses
map_df$Weight.mg <- as.numeric(map_df$Weight..g.) # Ensuring weight is numbers
map_df$Wing.Chord.mm <- as.numeric(map_df$Wing.Chord..mm.) # Ensuring wing chord is numbers
map_df$Right.Tarsus.mm <- as.numeric(map_df$Right.Tarsus..mm.) # Ensuring right tarsus is numbers
map_df$X9th.Primary.mm <- as.numeric(map_df$X9th.Primary..mm.) # Ensuring 9th primary is numbers
map_df$Box.Temperature <- as.numeric(map_df$Box.Temperature) # Ensuring box temp is numbers
```

```{r}
## Weight bar graph
ggplot(map_df, aes(x = Site, y = Weight.mg, fill = Site)) +
  stat_summary(fun = mean, geom = "bar") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  labs(title = "Average Weight by Site", x = "Site", y = "Weight (g)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

## Weight box plot — match BCI style (borders + no legend)
ggplot(map_df, aes(x = Site, y = Weight.mg, fill = Site)) +
  geom_boxplot(outlier.shape = NA, colour = "grey20") +
  labs(title = "Weight Distribution by Site",
       x = "Site", y = "Weight (g)") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")


## Manually assign Condition (MF & MD = Rural; all others = Waste)
map_df <- map_df %>%
  dplyr::mutate(
    Condition = ifelse(Site %in% c("MF","MD"), "Rural", "Waste"),
    Condition = factor(Condition, levels = c("Rural","Waste"))
  )

## Weight – compare by Condition (BCI-style, vertical y-axis title)
library(ggplot2)

ggplot(map_df, aes(x = Condition, y = Weight.mg, fill = Condition)) +
  geom_boxplot(outlier.shape = NA, colour = "grey20") +
  geom_jitter(width = 0.10, alpha = 0.6, size = 2, colour = "grey40") +
  scale_fill_manual(values = c(Rural = "#2C6DA4",   # blue
                               Waste = "#8C1513")) + # deep red
  labs(title = "Nestling weight by site condition",
       x = NULL,
       y = "Weight (g)") +  # switch to (mg) if that’s your unit
  theme_bw(base_size = 14) +
  theme(
    legend.position = "none",
    axis.text.x     = element_text(angle = 0, hjust = 0.5),
    plot.title      = element_text(hjust = 0.5)
  )
```

```{r}
## Right Tarsus bar graph
ggplot(map_df, aes(x = Site, y = Right.Tarsus.mm, fill = Site)) +
  stat_summary(fun = mean, geom = "bar") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  labs(title = "Average Right Tarsus by Site", x = "Site", y = "Right Tarsus (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

## Right Tarsus box plot
ggplot(map_df, aes(x = Site, y = Right.Tarsus.mm, fill = Site)) +
  geom_boxplot() +
  labs(title = "Right Tarsus Distribution by Site", x = "Site", y = "Right Tarsus (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
## 9th Primary bar graph
ggplot(map_df, aes(x = Site, y = X9th.Primary.mm, fill = Site)) +
  stat_summary(fun = mean, geom = "bar") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  labs(title = "Average 9th Primary by Site", x = "Site", y = "9th Primary (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

## 9th Primary box plot
ggplot(map_df, aes(x = Site, y = X9th.Primary.mm, fill = Site)) +
  geom_boxplot() +
  labs(title = "9th Primary Distribution by Site", x = "Site", y = "9th Primary (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
## Clutch Size bar graph
ggplot(map_df, aes(x = Site, y = Clutch.Size, fill = Site)) +
  stat_summary(fun = mean, geom = "bar") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2) +
  labs(title = "Average Clutch Size by Site", x = "Site", y = "Clutch Size") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

## Clutch Size box plot
ggplot(map_df, aes(x = Site, y = Clutch.Size, fill = Site)) +
  geom_boxplot() +
  labs(title = "Clutch Size by Site", x = "Site", y = "Clutch Size") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
##Filtering
write.csv(seqs, file= ##ASV Sequences CSV File)

seqs.fasta <- dataframe2fas(seqs, file= ##ASV Sequences FASTA File)

dat <-  phyloseq(otu_table(otu_df, taxa_are_rows = TRUE), # or FALSE if false
               tax_table(as.matrix(tax_df)),
               sample_data(map_df))

samplesums <- sort(sample_sums(dat))

write.csv(samplesums, file=##Read counts CSV)

plot(samplesums)

dat_lessHOST <- subset_taxa(dat, Kingdom=="Bacteria", Family!="Mitochondria")
write.csv(otu_table(dat_lessHOST),file=## OTU table CSV)
write.csv(tax_table(dat_lessHOST),file=## Tax table CSV)

rel_abun_all <- transform_sample_counts(dat_lessHOST, function(x) x/sum(x))
rel_abun_all_prune <- prune_taxa(taxa_sums(rel_abun_all) > 0.001,
                                 rel_abun_all)                           
```

```{r}
##SHANNON & SIMPSON    
dat_lessHOST_n5 <- prune_taxa(taxa_sums(dat_lessHOST)>5, dat_lessHOST)

min_lib <- min(sample_sums(dat))
dat_r <- rarefy_even_depth(dat_lessHOST,
                           sample.size=1000,
                           verbose=FALSE,
                           replace = FALSE)

dat_r1000 <- rarefy_even_depth(dat_lessHOST, 
                               sample.size=1000,
                               verbose=FALSE, 
                               replace=FALSE)

write.csv(otu_table(dat_r),file=##Rarefied OTU table CSV)

dat_lessHOST_phylum <- tax_glom(dat_lessHOST, taxrank="Genus")
write.csv(otu_table(dat_lessHOST_phylum),
          file=##noHOST OTU phylum table CSV)

theme_set(theme_bw())
colours <- createPalette(60, c("#ff0000", "#00ff00", "#0000ff"))
swatch(colours)
colours.un <- unname(colours)

alpha <- estimate_richness(dat_lessHOST, measures=c("Shannon", "Simpson"))
write.csv(alpha, file=##Shannon & Simpson data CSV)    

plot_richness(dat_lessHOST, x="SampleID", measures=c("Shannon", "Simpson"))

### rarefied ordination
rarefy.ord <- ordinate(dat_r, method="PCoA", distance = "bray")
prare.plot <- plot_ordination(dat_r, rarefy.ord,
                              color = "Site",
                              label = "SampleID",
                              axes = c(1,2),
                              title = "Bray-Curtis rarefy")

# extract the sample_data into a data.frame
sd <- data.frame(sample_data(dat_r))

# create a new column
sd$Pollution <- ifelse(sd$Site %in% c("BRL","BWTP","WBS","DWTP"),
                       "Waste","Rural")

# push the updated sample_data back into the phyloseq object
sample_data(dat_r) <- sd

# 1. Re-level and rename your Site factor
sample_data(dat_r)$Site <- factor(sample_data(dat_r)$Site,
    levels = c("BRL","BWTP","DWTP","MD","MF","WBS"),
    labels = c("BRL","BWTP","DWTP","MD","MF","WBS")
)

# 2. Now regenerate the plot with color mapping
p <- plot_richness(dat_r,
                   x        = "Site",
                   measures = c("Shannon","Simpson"),
                   color    = "Pollution") +
     scale_color_manual(values = c("Rural"="blue",
                                   "Waste"    ="red")) +
     labs(color = "Site Condition") +
     theme_bw(base_size=14) +
     theme(
       axis.text.x = element_text(angle = 45, hjust = 1)  # rotate labels
     )
``` 

```{r}

### rarefied ordination
rarefy.ord <- ordinate(dat_r, method="PCoA", distance = "bray")
prare.plot <- plot_ordination(dat_r, rarefy.ord,
                           color = "Site",
                           label = "SampleID",
                           axes = c(1,2),
                           title = "Bray-Curtis rarefy")


library(phyloseq)
library(ggplot2)
library(ggrepel)

# 1) Relative abundance 
dat_rel <- transform_sample_counts(dat, function(x) x / sum(x))

# 2) Add Replicate letter (A–E) to sample_data
sd <- data.frame(sample_data(dat_rel))
sd$Rep <- factor(sub(".*-([A-E])$", "\\1", sd$SampleID), levels = c("A","B","C","D","E"))
sample_data(dat_rel)$Rep <- sd$Rep

# 3) PCoA (Bray–Curtis)
ord  <- ordinate(dat_rel, method = "PCoA", distance = "bray")
eig  <- ord$values$Relative_eig * 100
axis1 <- sprintf("PCoA1 [%0.1f%%]", eig[1])
axis2 <- sprintf("PCoA2 [%0.1f%%]", eig[2])

# 4) Plot (only one label layer)
p <- plot_ordination(dat_rel, ord, type = "samples",
                     color = "Site", axes = c(1,2)) +  # ← no label= argument here
  geom_point(aes(shape = Rep), size = 3.5, stroke = 0.7, color = "black") +
  geom_point(aes(color = Site, shape = Rep), size = 3, alpha = 0.9) +
  geom_text(aes(label = SampleID, color = Site), size = 2.4, vjust = -1.2, alpha = 0.8) +
  scale_shape_manual(
    name = "Box",
    values = c(A = 16, B = 15, C = 17, D = 18, E = 8)
  ) +
  labs(title = "Bray–Curtis PCoA (no rarefaction)",
       x = axis1, y = axis2, color = "Site") +
  theme_bw(base_size = 14) +
  theme(
    plot.title       = element_text(hjust = 0.5),
    panel.grid.major = element_line(color = "grey90"),
    panel.grid.minor = element_blank(),
    legend.position  = "right"
  )
     ) 

# 5. Extract per-sample PCoA coordinates
scores <- as.data.frame(ord$vectors)   # ord$vectors = site scores
scores$SampleID <- rownames(scores)

# Keep only first 3 axes (add more if needed)
scores <- scores[, c("SampleID","Axis.1","Axis.2","Axis.3")]

# Rename columns for clarity
colnames(scores) <- c("SampleID","BrayCurtis_PCoA1","BrayCurtis_PCoA2","BrayCurtis_PCoA3")

# Add metadata (Site, Pollution, etc.)
meta <- data.frame(sample_data(dat_rel))
meta$SampleID <- rownames(meta)

scores_annot <- dplyr::left_join(meta, scores, by = "SampleID")

# Save to CSV
outpath <- #CSV file
readr::write_csv(scores_annot, outpath)
```          

```{r}
##Rarefaction Curve
library(phyloseq); library(vegan); library(dplyr); library(ggplot2)

# Extract OTU matrix
otu_mat <- as(otu_table(dat), "matrix")
if(taxa_are_rows(dat)) otu_mat <- t(otu_mat)

# Define a wider range of depths: from 0 up to, e.g., 5000 reads
maxDepth <- max(rowSums(otu_mat))
depths   <- seq(0, min(maxDepth, 5000), by = 100)

# Compute richness at each depth
richness_df <- bind_rows(lapply(depths, function(d) {
  data.frame(
    depth    = d,
    richness = rarefy(otu_mat, sample = d)
  )
}), .id = NULL)

# Summarize mean ± SD
summary_df <- richness_df %>%
  group_by(depth) %>%
  summarize(
    mean_rich = mean(richness),
    sd_rich   = sd(richness),
    .groups    = "drop"
  )

# Plot 0–5000 reads, with minDepth line at 556
ggplot(summary_df, aes(x = depth, y = mean_rich)) +
  geom_ribbon(aes(ymin = mean_rich - sd_rich,
                  ymax = mean_rich + sd_rich),
              fill = "grey80", alpha = 0.6) +
  geom_line(size = 1) +
  geom_vline(xintercept = minDepth, linetype = "dashed", color = "red") +
  coord_cartesian(xlim = c(0, 1000)) +
  labs(
    title = "Rarefaction Curve to 5 000 Reads (mean ±1 SD)",
    x     = "Sequencing depth (reads)",
    y     = "Mean observed ASVs"
  ) +
  theme_bw(base_size = 14)

```

          

```{r}
library ('SiZer')
library('segmented')
library('car')
library(nlme)
library (lme4)
library(ggplot2)
library(ggeffects)
library(arm)
library(MuMIn)
library(AICcmodavg)
library(robustlmm)
library(memisc)
library(car)
library(lmerTest)
library(influence.ME)
library(dplyr)
library(performance)

##AICC Analysis

# 1) Extract your sample_data into a data.frame
df <- data.frame(sample_data(dat_r))   # or sample_data(dat) if you didn't rarefy

# 2) (Re)compute Shannon if needed
# If you already ran estimate_richness(), skip this. Otherwise:
sh <- estimate_richness(dat_r, measures = "Shannon")
df$shannon_diversity <- sh$Shannon

# 3) Create your Pollution factor (if you haven't already)
df$Pollution <- factor(ifelse(df$Site %in% c("BRL","BWTP","WBS","DWTP"),
                              "Polluted","Non-polluted"),
                       levels = c("Non-polluted","Polluted"))

# 4) Make sure your grouping vars are factors
df$Site <- factor(df$Site)
df$SampleID   <- factor(df$SampleID)  # if you have an ID column

options(na.action = "na.fail")
#mixed model with site as a random factor and pollution (polluted vs unpolluted) as a fixed factor
#lm.ip1<-lmer(shannon_diversity~Pollution+Weight.mg+Clutch.Size+Right.Tarsus.mm+Wing.Chord.mm+X9th.Primary.mm+ (1|Site), REML=FALSE,na.action = "na.fail", data=df)
#summary(lm.ip1)
#ip1models<-dredge(lm.ip1)


a1<-lm(shannon_diversity~Site+Weight.mg+Clutch.Size+Right.Tarsus.mm+Wing.Chord.mm+X9th.Primary.mm, na.action="na.fail", data=df)
a1models<-dredge (a1)
a1models

#lists top models with lowest AICc
a1models

#rerun best model on its own
best<-shannon_diversity~ #add factors

#check assumptions of best model
check_model(best)

#summary
summary(best)

alt.est.a <- influence(lm.ip1, "Site")

#another outlier test
cooks.distance(alt.est.a)

#confidence intervals which are the same as p values
confint.merMod(lm.ip1)

#running a linear model without a random factor
a1<-lm(shannon_diversity~Site+Clutch.Size+Weight.mg+Right.Tarsus.mm+Wing.Chord.mm+X9th.Primary.mm, na.action="na.fail", data= df)
a1models<-dredge (a1)
```

```{r}
## ────────────────────────────────────────────────────────────────
## BODY-CONDITION INDEX (BCI) – compare among sites
## ────────────────────────────────────────────────────────────────

# 1. Fit mass-on-wing regression (keeps NA rows so lengths match)
bci_lm <- lm(Weight.mg ~ Wing.Chord.mm,
             data      = df,
             na.action = na.exclude)

# 2. Add residuals to df and to the phyloseq sample_data
df$BCI_resid <- resid(bci_lm)
sample_data(dat_r)$BCI_resid <- df$BCI_resid   # synchronise

# 3. Visualise BCI by Site
library(ggplot2)

ggplot(df, aes(Site, BCI_resid, fill = Site)) +
  geom_boxplot(outlier.shape = NA, colour = "grey20") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residual body mass (BCI) by site",
       y      = "Body-condition index (g)", x = "Site") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")

# 4. Statistical test: does BCI differ among sites?
#    a) Welch one-way ANOVA (robust to unequal variances)
oneway <- oneway.test(BCI_resid ~ Site, data = df)
oneway

#    b) If significant, run pairwise comparisons (Tukey on lm or Games-Howell)
#       Create a linear model with Site as factor
lm_site <- lm(BCI_resid ~ Site, data = df)
#       Tukey HSD with unequal n but equal variances assumption:
library(multcomp)
cld(glht(lm_site, linfct = mcp(Site = "Tukey")))

## ──────────────────────────────────────────────────────────────
##  Per-site body-condition summary (median, IQR, n)
## ──────────────────────────────────────────────────────────────
library(dplyr)

site_bci_stats <- df %>% 
  group_by(Site) %>% 
  summarise(
    n           = n(),
    median_BCI  = median(BCI_resid, na.rm = TRUE),
    IQR_BCI     = IQR   (BCI_resid, na.rm = TRUE),
    .groups     = "drop"
  ) %>% 
  arrange(median_BCI)      # optional: sort from lowest to highest

```

```{r}
# ────────────────────────────────────────────────────────────────
# Robust BCI extractor (handles snake_case & mg→g)
# ────────────────────────────────────────────────────────────────
library(dplyr)
library(readr)

# Ensure an ID column is present
if (!"SampleID" %in% names(df)) {
  df$SampleID <- df$sample_id %||% rownames(df)
}

# 1) Detect columns present in *your* df
weight_candidates <- c(
  # prefer grams
  "weight_g","Weight.g","weight", "mass_g","Mass_g",
  # fallbacks in mg
  "weight_mg","Weight.mg"
)
wing_candidates <- c(
  "wing_chord_mm","Wing.Chord.mm","wing_mm","Wing.mm",
  # fallback “second” column names you listed
  "wing_chord_mm_2","Wing.Chord.mm.2"
)
site_candidates <- c("site","Site")

pick_first <- function(cands, tbl) {
  hit <- cands[cands %in% names(tbl)]
  if (length(hit)) hit[1] else NA_character_
}

w_col    <- pick_first(weight_candidates, df)
wing_col <- pick_first(wing_candidates,   df)
site_col <- pick_first(site_candidates,   df)

if (is.na(w_col) || is.na(wing_col)) {
  stop("Could not find weight (tried: ", paste(weight_candidates, collapse=", "),
       ") or wing (tried: ", paste(wing_candidates, collapse=", "),
       ") in df. Have: ", paste(names(df), collapse=", "))
}

# 2) Coerce numeric and normalize units (prefer grams; convert mg→g)
df[[w_col]]    <- suppressWarnings(as.numeric(df[[w_col]]))
df[[wing_col]] <- suppressWarnings(as.numeric(df[[wing_col]]))

# If we only have mg, convert to grams for the regression and output
weight_is_mg <- grepl("mg$", w_col, ignore.case = TRUE)
weight_vec_g <- if (weight_is_mg) df[[w_col]] / 1000 else df[[w_col]]

# 3) (Re)compute BCI if needed (residuals of mass ~ wing chord)
if (!"bci_resid" %in% names(df) || all(is.na(df$bci_resid))) {
  bci_lm <- lm(weight_vec_g ~ df[[wing_col]], na.action = na.exclude)
  df$bci_resid <- resid(bci_lm)
}

# 4) Build tidy output with consistent names
bci_tbl <- tibble(
  SampleID      = df$SampleID,
  Site          = if (!is.na(site_col)) df[[site_col]] else NA,
  Weight_g      = weight_vec_g,
  WingChord_mm  = df[[wing_col]],
  BCI_resid     = df$bci_resid
)

# 5) Save & preview
write_csv(bci_tbl, ##BCI CSV)

```        

```{r}
## ────────────────────────────────────────────────────────────────
##  Site-by-site BCI summary + pairwise Welch t-tests (BH adj)
## ────────────────────────────────────────────────────────────────
library(dplyr)      # summarise(), pipes
library(multcomp)   # cld() for letters
library(rstatix)    # tidy pairwise_t_test()

# 0. Ensure residual BCI column exists ---------------------------
if (!"BCI_resid" %in% names(df)) {
  bci_lm       <- lm(Weight.mg ~ Wing.Chord.mm, data = df,
                     na.action = na.exclude)   # keep NA rows
  df$BCI_resid <- resid(bci_lm)
}

# 1. Descriptive stats ------------------------------------------
site_stats <- df %>% 
  group_by(Site) %>% 
  summarise(
    n        = n(),
    mean_BCI = mean(BCI_resid, na.rm = TRUE),
    sd_BCI   = sd(BCI_resid,   na.rm = TRUE),
    se_BCI   = sd_BCI / sqrt(n),
    .groups  = "drop"
  )
print(site_stats)

# 2a. BH-adjusted Welch tests – tidy tibble ----------------------
pairwise_df <- pairwise_t_test(
  data            = df,
  formula         = BCI_resid ~ Site,
  p.adjust.method = "BH"          # BH correction
)
# View just the adjusted p values
pairwise_df %>% select(group1, group2, p.adj) %>% arrange(p.adj)

# 2b. Same thing as a symmetric matrix (base-R) ------------------
pair_mat <- pairwise.t.test(
  x               = df$BCI_resid,
  g               = df$Site,
  p.adjust.method = "BH",
  pool.sd         = FALSE          # Welch unequal-var
)
pair_mat$p.value           # prints the matrix

# 3. Compact letters display for plotting captions --------------
lm_site <- lm(BCI_resid ~ Site, data = df)
tukey   <- glht(lm_site, linfct = mcp(Site = "Tukey"))
letters <- cld(tukey)$mcletters$Letters
print(letters)

```

```{r}
# ── Setup ───────────────────────────────────────────────────────────────────────
library(dplyr)
library(ggplot2)
library(janitor)
library(lme4)

# If your metadata is in the phyloseq object, start from there:
df <- data.frame(sample_data(dat_r)) |> as_tibble()

# Clean names like "Weight (g)" -> weight_g
df <- clean_names(df)

# Helper to pick a single column by candidate patterns
pick_col <- function(data, patterns, desc){
  idx <- Reduce(`|`, lapply(patterns, function(p) grepl(p, names(data), ignore.case = TRUE)))
  hits <- names(data)[idx]
  if (length(hits) == 0) stop(sprintf("Couldn't find a column for %s. Checked patterns: %s",
                                      desc, paste(patterns, collapse=", ")), call. = FALSE)
  if (length(hits) > 1) {
    # If multiple, prefer exact/common names if present
    preferred <- c("weight_g","weight","mass_g","body_mass_g","wing_chord_mm","wing_chord","wing_mm")
    hit <- intersect(preferred, hits)
    if (length(hit) >= 1) return(hit[1])
    warning(sprintf("Multiple candidates for %s found: %s. Using %s.",
                    desc, paste(hits, collapse=", "), hits[1]))
    return(hits[1])
  }
  hits[1]
}

# Try to find weight (g) and wing chord (mm)
weight_col <- pick_col(df,
  patterns = c("^weight[_]*g$", "^weight$", "mass[_]*g", "body[_]*mass[_]*g"),
  desc = "weight (g)"
)
wing_col <- pick_col(df,
  patterns = c("^wing[_]*chord[_]*mm$", "^wing[_]*chord$", "^wing[_]*mm$"),
  desc = "wing chord (mm)"
)

# ── Compute residual BCI (mass ~ wing chord) ────────────────────────────────────
if (!"bci_resid" %in% names(df)) {
  # Use grams (your data appear to be in g, not mg)
  bci_formula <- reformulate(wing_col, response = weight_col)
  bci_lm <- lm(bci_formula, data = df, na.action = na.exclude)
  df$bci_resid <- resid(bci_lm)
}

# ── Define Pollution factor ─────────────────────────────────────────────────────
polluted_sites <- c("BRL", "BWTP", "WBS", "DWTP")  # edit if needed

# Ensure 'site' column exists (clean_names likely made it `site`)
if (!"site" %in% names(df)) stop("No 'site' column found after clean_names().", call. = FALSE)

df <- df |>
  mutate(
    Pollution = factor(ifelse(site %in% polluted_sites, "Waste", "Rural"),
                       levels = c("Rural","Waste"))
  )

# ── Write back to phyloseq object (so ordinations etc. can use it) ─────────────
# Align by row order (sample_data rows should match df rows if created directly from it)
sample_data(dat_r)$Pollution <- df$Pollution
sample_data(dat_r)$BCI_resid <- df$bci_resid

# ── Plot: BCI by pollution class ────────────────────────────────────────────────
p <- ggplot(df, aes(Pollution, bci_resid, fill = Pollution)) +
  geom_boxplot(outlier.shape = NA, colour = "grey20") +
  geom_jitter(width = 0.1, alpha = 0.4, size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c("Rural" = "steelblue", "Waste" = "firebrick")) +
  labs(title = "Residual body mass (BCI) by site condition",
       x = NULL, y = "Body-condition index (g residuals)") +
  theme_bw(base_size = 14) +
  theme(legend.position = "none")
print(p)

# ── Welch two-sample t-test ────────────────────────────────────────────────────
t_poll <- t.test(bci_resid ~ Pollution, data = df)
print(t_poll)

# Cohen's d (pooled SD)
polluted    <- df$bci_resid[df$Pollution == "Waste"]
nonpolluted <- df$bci_resid[df$Pollution == "Rural"]

s_pool <- sqrt(((length(polluted)-1)*var(polluted) +
                (length(nonpolluted)-1)*var(nonpolluted)) /
               (length(polluted) + length(nonpolluted) - 2))

d <- (mean(polluted, na.rm = TRUE) - mean(nonpolluted, na.rm = TRUE)) / s_pool
cat("Cohen's d (Waste - Rural):", round(d, 3), "\n")

# ── Mixed model controlling for site ───────────────────────────────────────────
# Use site as a random intercept; ensure it's a factor
df$site <- factor(df$site)
bci_lmm <- lmer(bci_resid ~ Pollution + (1 | site), data = df)
summary(bci_lmm)

## ──────────────────────────────────────────────────────────────
##  4.  Descriptives, Welch t-test, and Cohen’s d
## ──────────────────────────────────────────────────────────────
library(dplyr)
library(effectsize)   # install.packages("effectsize")  if needed

# 4a. Descriptive stats ----------------------------------------
bci_summary <- df %>% 
  group_by(Pollution) %>% 
  summarise(
    n        = n(),
    mean_g   = mean(bci_resid, na.rm = TRUE),
    sd_g     = sd  (bci_resid, na.rm = TRUE),
    .groups  = "drop"
  )

# 4b. Welch t-test --------------------------------------------
t_poll <- t.test(bci_resid ~ Pollution, data = df)

# Print result in the standard R format
print(t_poll)               
```
                            
```{r}
# ──────────────────────────────────────────────────────────────── ANOVA comparison of alpha diversity results
# 0) Packages ----------------------------------------------------
library(phyloseq)
library(dplyr)
library(tibble)     # rownames_to_column()
library(rstatix)    # Games-Howell, if needed
library(car)        # Levene’s

# ────────────────────────────────────────────────────────────────
# 1) Alpha-diversity table ---------------------------------------
alpha_df <- estimate_richness(dat, measures = "Shannon") %>%
  {                               # add SampleID only if it's NOT there
    if (!"SampleID" %in% colnames(.)) {
      rownames_to_column(., "SampleID")
    } else .
  }

cat("\nalpha_df columns →", paste(colnames(alpha_df), collapse = ", "), "\n")

# ────────────────────────────────────────────────────────────────
# 2) Metadata table  (NEVER duplicates) --------------------------
meta_df <- tibble(
  SampleID = sample_names(dat),         # guaranteed unique
  Site      = sample_data(dat)$Site
)

cat("meta_df  columns →", paste(colnames(meta_df), collapse = ", "), "\n")

# ────────────────────────────────────────────────────────────────
# 3) Merge & sanity-check ----------------------------------------
alpha_df <- left_join(alpha_df, meta_df, by = "SampleID")

# Confirm uniqueness
stopifnot(anyDuplicated(colnames(alpha_df)) == 0)
cat("Merged OK.  Columns are unique.\n")

# ────────────────────────────────────────────────────────────────
# 4) ANOVA + post-hocs ------------------------------------------
anova_res  <- aov(Shannon ~ Site, data = alpha_df)
levene_res <- leveneTest(Shannon ~ Site, data = alpha_df)

if (levene_res$`Pr(>F)`[1] < 0.05) {
  message("⚠️  Variances unequal → using Welch + Games-Howell")
  welch_res <- oneway.test(Shannon ~ Site, data = alpha_df,
                           var.equal = FALSE)
  gh_res <- alpha_df %>% games_howell_test(Shannon ~ Site)
  print(welch_res); print(gh_res)
} else {
  tukey_res <- TukeyHSD(anova_res)
  print(summary(anova_res)); print(tukey_res)
}
```

```{r}
## Barcharts for taxonomic composition:
### top 20 phyla
top20 <- names(sort(taxa_sums(dat_lessHOST), decreasing=TRUE))[1:20]
dat.top20 <- transform_sample_counts(dat, function(OTU) OTU/sum(OTU))
dat.top20 <- prune_taxa(top20, dat.top20)

## plotting:
### quick look at plot
plot_bar(dat.top20, fill='Genus')
plot_bar(dat.top20, fill='Phylum')
```

```{r}
# ─── 0) Libraries ─────────────────────────────────────────────────────────────
library(phyloseq)
library(DESeq2)
library(apeglm)
library(dplyr)
library(tibble)

# ─── 1) Pre‐filter: keep taxa in ≥10% of samples ──────────────────────────────
minSamples <- ceiling(0.1 * nsamples(dat))         # at least this many samples
otu_mat    <- as(otu_table(dat), "matrix")        # extract count matrix
if (!taxa_are_rows(dat)) otu_mat <- t(otu_mat)     # ensure taxa in rows
presence   <- rowSums(otu_mat > 0)                # count non‐zero per taxon
keep_taxa  <- presence >= minSamples              # TRUE for taxa to keep
dat_filt   <- prune_taxa(keep_taxa, dat)          # prune phyloseq object

message(sum(keep_taxa), " taxa kept out of ", ntaxa(dat))

# ─── 2) Ensure your grouping factor ─────────────────────────────────────────
sample_data(dat_filt)$Site <- factor(sample_data(dat_filt)$Site)

# ─── 3) DESeq2 object & model fit ────────────────────────────────────────────
dds <- phyloseq_to_deseq2(dat_filt, ~ Site)
dds <- DESeq(dds,
             sfType  = "poscounts",    # handles zeros
             test    = "Wald",
             fitType = "parametric")

# ─── 4) Examine available contrasts ──────────────────────────────────────────
resultsNames(dds)
# e.g. "Intercept", "Site_BWTP_vs_BRL", "Site_DWTP_vs_BRL", …

# ─── 5) Shrink log₂‐fold‐changes with apeglm ─────────────────────────────────
resLFC <- lfcShrink(dds,
                    coef = "Site_DWTP_vs_BRL",
                    type = "apeglm")

# ─── 6) Extract significant ASVs ────────────────────────────────────────────
sigASVs <- as.data.frame(resLFC) %>%
  rownames_to_column(var = "ASV") %>%
  filter(padj < 0.05) %>%
  arrange(padj)

head(sigASVs)

```

```{r}
library(phyloseq)
library(dplyr)
library(ggplot2)
library(ggrepel)

# 0) Pick your reference site and phyla of interest
ref_site <- "DWTP"
phyla_of_interest <- c("Chlamydiota", "Bacillota", "Actinomycetota", "Bacteroidota", "Pseudomonadota")  # <- Add your phyla here!

# 1) Agglomerate to Phylum
ps_phylum <- tax_glom(dat, taxrank = "Phylum")

# 2) Melt and compute per-sample totals
df_all <- psmelt(ps_phylum) %>%
  group_by(Sample) %>%
  mutate(sample_total = sum(Abundance)) %>% 
  ungroup()

# 3) Initialize lists to store results
plots  <- list()
ttests <- list()

# 4) Loop through each phylum
for (ref_phylum in phyla_of_interest) {
  
  # Subset for the current phylum
  df <- df_all %>%
    filter(Phylum == ref_phylum) %>%
    group_by(Site, Sample) %>%
    summarise(
      relAbund = sum(Abundance) / unique(sample_total),
      .groups  = "drop"
    )
  
  # Compute site means and SEM (as %)
  site_stats <- df %>%
    group_by(Site) %>%
    summarise(
      meanRA = mean(relAbund) * 100,
      semRA  = sd(relAbund) / sqrt(n()) * 100,
      .groups = "drop"
    )
  
  # Compute differences vs reference site
  ref_mean <- site_stats %>% filter(Site == ref_site) %>% pull(meanRA)
  
  site_stats <- site_stats %>%
    mutate(
      diff    = meanRA - ref_mean,
      pctDiff = round(diff / ref_mean * 100, 1)
    )
  
  # Make plot
  p <- ggplot(site_stats, aes(x = Site, y = diff)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_pointrange(aes(ymin = diff - semRA,
                        ymax = diff + semRA),
                    size = 0.8) +
    geom_text_repel(aes(label = paste0(ifelse(pctDiff > 0, "+", ""),
                                       pctDiff, "%"),
                         y = diff),
                    nudge_y = ifelse(site_stats$diff > 0, 2, -2),
                    size = 4,
                    segment.size = 0.3) +
    coord_flip() +
    labs(
      title = paste0("Difference in mean ", ref_phylum,
                     " rel. abundance vs ", ref_site, " (± SEM)"),
      x = NULL,
      y = "Difference in mean rel. abundance (%)"
    ) +
    theme_bw(base_size = 14) +
    theme(
      panel.grid.major.y = element_blank(),
      panel.grid.minor   = element_blank()
    )
  
  # Save plot
  plots[[ref_phylum]] <- p
  
  # Save t-test results with Phylum name attached
  ttests[[ref_phylum]] <- list(
    phylum = ref_phylum,
    result = pairwise.t.test(df$relAbund, df$Site,
                             p.adjust.method = "BH",
                             pool.sd = FALSE)
  )
}


# 6) Look at t-test results (example)
ttests[["Chlamydiota"]]   # Shows the actual pairwise t-test table
ttests[["Bacillota"]]    # Bacillota pairwise test
ttests[["Actinomycetota"]]    # Bacillota pairwise test
ttests[["Pseudomonadota"]]    # Bacillota pairwise test
ttests[["Bacteroidota"]]    # Bacillota pairwise test
```

```{r}
## ────────────────────────────────────────────────────────────────
## BLOCK 1 — DATA PREP
## Inputs expected in environment:
##   dat: phyloseq object with counts + taxonomy (has Phylum)
##   ref_site: character (e.g., "DWTP")
##   phyla_of_interest: character vector of phyla to evaluate
## ────────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(phyloseq)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(ggrepel)
  library(rstatix)   # shapiro_test, levene_test, kruskal_test, dunn_test
})

# Option: drop sites that are 100% zeros for a given phylum (no information)
drop_all_zero_sites <- TRUE
label_nudge <- 2  # for % labels on the plot

# 1) Agglomerate to Phylum
ps_phylum <- tax_glom(dat, taxrank = "Phylum")

# 2) Long data + per-sample totals
df_all <- psmelt(ps_phylum) %>%
  group_by(Sample) %>%
  mutate(sample_total = sum(Abundance)) %>%
  ungroup()

# 3) Initialize containers used by Block 2
plots     <- list()  # per-phylum ggplot objects (in-memory only)
tests     <- list()  # per-phylum stats results
summaries <- list()  # tidy-ish posthoc tables per phylum (in-memory only)

```

```{r}
## ────────────────────────────────────────────────────────────────
## BLOCK 2 — RUN TESTS
## For each phylum: per-sample relative abundance ~ Site
## Primary: one-way ANOVA + TukeyHSD (no Welch)
## Fallback: Kruskal–Wallis + Dunn (BH) when assumptions fail
## ────────────────────────────────────────────────────────────────

for (ref_phylum in phyla_of_interest) {

  # Per-sample relative abundance for this phylum
  df <- df_all %>%
    filter(Phylum == ref_phylum) %>%
    group_by(Site, Sample) %>%
    summarise(relAbund = sum(Abundance) / unique(sample_total),
              .groups = "drop")

  # Optionally remove sites with all-zero relAbund for this phylum
  if (drop_all_zero_sites) {
    site_nonzero <- df %>%
      group_by(Site) %>%
      summarise(all_zero = all(relAbund == 0), .groups = "drop") %>%
      filter(!all_zero) %>%
      pull(Site)
    df <- df %>% filter(Site %in% site_nonzero)
  }

# Ensure Site is a factor (prevents "group coerced to factor" warnings)
# Put ref_site first in the order (nice for tables/plots), then the rest alphabetically
site_levels <- c(ref_site, sort(unique(df$Site[df$Site != ref_site])))
df <- df %>% mutate(Site = factor(Site, levels = site_levels))

  
  # Guard: need ≥2 sites and reasonable sample size
  if (dplyr::n_distinct(df$Site) < 2 || nrow(df) < 3) {
    warning(paste0("Skipping ", ref_phylum, ": not enough data across sites."))
    next
  }

  # Site means/SEMs for difference-vs-reference plot
  site_stats <- df %>%
    group_by(Site) %>%
    summarise(
      meanRA = mean(relAbund) * 100,
      semRA  = sd(relAbund) / sqrt(n()) * 100,
      n      = n(),
      .groups = "drop"
    )

  # Reference must exist after any filtering
  if (!ref_site %in% site_stats$Site) {
    warning(paste0("Reference site '", ref_site, "' not present for ", ref_phylum))
    next
  }

  ref_mean <- site_stats %>% filter(Site == ref_site) %>% pull(meanRA)
  site_stats <- site_stats %>%
    mutate(
      diff    = meanRA - ref_mean,
      pctDiff = round(ifelse(ref_mean == 0, NA_real_, diff / ref_mean * 100), 1)
    )

  # ── Assumptions: robust checks ────────────────────────────────
  by_site <- df %>%
    group_by(Site) %>%
    summarise(n = n(),
              sd_rel = sd(relAbund),
              .groups = "drop")

  # If any site has n<3 or sd==0 (constant values), force nonparametric
  force_nonparam <- any(by_site$n < 3 | by_site$sd_rel == 0, na.rm = TRUE)

  # Safe Shapiro per site (only when n>=3 & sd>0)
  shapiro_by_site <- df %>%
    group_by(Site) %>%
    summarise(
      shapiro_p = if (n() >= 3 && sd(relAbund) > 0) {
        stats::shapiro.test(relAbund)$p.value
      } else {
        NA_real_
      },
      .groups = "drop"
    )

  # Levene (guard errors)
  lev_p <- tryCatch(
    rstatix::levene_test(df, relAbund ~ Site)$p,
    error = function(e) NA_real_
  )

  normal_ok <- !force_nonparam && all(shapiro_by_site$shapiro_p > 0.05, na.rm = TRUE)
  homo_ok   <- !is.na(lev_p) && lev_p > 0.05

  # ── Tests: ANOVA + Tukey (primary) OR KW + Dunn (fallback) ────
  if (normal_ok && homo_ok) {
    aov_model <- aov(relAbund ~ Site, data = df)
    aov_sum   <- summary(aov_model)
    tuk       <- TukeyHSD(aov_model)

    tests[[ref_phylum]] <- list(
      phylum      = ref_phylum,
      method      = "ANOVA + TukeyHSD",
      assumptions = list(by_site = by_site, shapiro = shapiro_by_site, levene_p = lev_p),
      anova       = aov_sum,
      posthoc     = tuk
    )

    tuk_df <- as.data.frame(tuk$Site)
    tuk_df$comparison <- rownames(tuk_df)
    summaries[[ref_phylum]] <- tuk_df %>%
      dplyr::select(comparison, diff = diff, lwr = lwr, upr = upr, p_adj = `p adj`) %>%
      dplyr::mutate(phylum = ref_phylum, method = "TukeyHSD")

  } else {
    kw   <- rstatix::kruskal_test(df, relAbund ~ Site)
    dunn <- rstatix::dunn_test(df, relAbund ~ Site, p.adjust.method = "BH")

    tests[[ref_phylum]] <- list(
      phylum      = ref_phylum,
      method      = "Kruskal–Wallis + Dunn (BH)",
      assumptions = list(by_site = by_site, shapiro = shapiro_by_site, levene_p = lev_p),
      kruskal     = kw,
      posthoc     = dunn
    )

    summaries[[ref_phylum]] <- dunn %>%
      dplyr::select(group1, group2, p.adj) %>%
      dplyr::rename(comparison_paired_groups = group1,
                    comparison_against       = group2,
                    p_adj                    = p.adj) %>%
      dplyr::mutate(phylum = ref_phylum, method = "Dunn (BH)")
  }

  # ── Optional in-memory plot: difference vs reference (±SEM) ───
  plots[[ref_phylum]] <- ggplot(site_stats, aes(x = Site, y = diff)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_pointrange(aes(ymin = diff - semRA, ymax = diff + semRA), size = 0.8) +
    geom_text_repel(
      aes(label = ifelse(is.na(pctDiff), "NA", paste0(ifelse(pctDiff > 0, "+", ""), pctDiff, "%")),
          y = diff),
      nudge_y = ifelse(site_stats$diff > 0, label_nudge, -label_nudge),
      size = 4, segment.size = 0.3
    ) +
    coord_flip() +
    labs(
      title = paste0("Difference in mean ", ref_phylum,
                     " relative abundance vs ", ref_site, " (± SEM)"),
      x = NULL,
      y = "Difference in mean relative abundance (%)"
    ) +
    theme_bw(base_size = 14) +
    theme(panel.grid.major.y = element_blank(),
          panel.grid.minor   = element_blank())
}                                     
```   

```{r}
## ===== Pairwise p-value tables (readable) =====
library(dplyr)
library(stringr)

# star helper
.star <- function(p) ifelse(is.na(p), "", ifelse(p<0.001,"***",ifelse(p<0.01,"**",ifelse(p<0.05,"*",""))))

# Build one tidy table of pairwise adjusted p-values for all phyla
pairwise_pvals <- bind_rows(lapply(names(tests), function(ph) {
  x <- tests[[ph]]
  if (is.null(x$posthoc)) return(NULL)

  if (identical(x$method, "ANOVA + TukeyHSD")) {
    tk <- as.data.frame(x$posthoc$Site)
    tk$comparison <- rownames(tk)
    tk %>%
      transmute(
        phylum     = ph,
        method     = "TukeyHSD",
        comparison = comparison,                # "A-B"
        p_adj      = `p adj`,
        sig        = .star(p_adj)
      )
  } else { # Kruskal–Wallis + Dunn (BH)
    dn <- x$posthoc
    dn %>%
      transmute(
        phylum     = ph,
        method     = "Dunn (BH)",
        comparison = paste0(group1, " - ", group2),
        p_adj      = p.adj,
        sig        = .star(p_adj)
      )
  }
}), .id = NULL) %>%
  arrange(phylum, p_adj) %>%
  mutate(p_adj = signif(p_adj, 3))  # nicer rounding

# ==== Quick prints ====
# All phyla, all pairs:
pairwise_pvals

pairwise_pvals %>% filter(p_adj < 0.05)
```                          

```{r}

library(phyloseq)
library(dplyr)
library(ggplot2)
library(ggrepel)

# Genus names of interest (from screenshot, cleaned)
genera_of_interest <- c(
  "Apilactobacillus",
  "Brevundimonas",
  "Candidatus Rhabdochlamydia",
  "Catellicoccus",
  "Commensalibacter",
  "Dysgonomonas",
  "Enterococcus",
  "Fructobacillus",
  "Klebsiella",
  "Leuconostoc",
  "Morganella",
  "Paenibacillus",
  "Providencia",
  "Rickettsiella",
  "Serratia",
  "Stenotrophomonas",
  "Weissella"
)

# Reference site
ref_site <- "DWTP"

# 1) Agglomerate at Genus level
ps_genus <- tax_glom(dat, taxrank = "Genus")

# 2) Melt and compute per-sample totals
df_all <- psmelt(ps_genus) %>%
  group_by(Sample) %>%
  mutate(sample_total = sum(Abundance)) %>% 
  ungroup()

# 3) Initialize output containers
plots  <- list()
ttests <- list()

# 4) Loop through each genus
for (ref_genus in genera_of_interest) {
  
  # Subset to current genus
  df <- df_all %>%
    filter(Genus == ref_genus) %>%
    group_by(Site, Sample) %>%
    summarise(
      relAbund = sum(Abundance) / unique(sample_total),
      .groups  = "drop"
    )
  
  # Compute site means and SEM
  site_stats <- df %>%
    group_by(Site) %>%
    summarise(
      meanRA = mean(relAbund) * 100,
      semRA  = sd(relAbund) / sqrt(n()) * 100,
      .groups = "drop"
    )
  
  # Reference site mean
  ref_mean <- site_stats %>% filter(Site == ref_site) %>% pull(meanRA)
  
  # Add diffs
  site_stats <- site_stats %>%
    mutate(
      diff    = meanRA - ref_mean,
      pctDiff = round(diff / ref_mean * 100, 1)
    )
  
  # Plot
  p <- ggplot(site_stats, aes(x = Site, y = diff)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    geom_pointrange(aes(ymin = diff - semRA,
                        ymax = diff + semRA),
                    size = 0.8) +
    geom_text_repel(aes(label = paste0(ifelse(pctDiff > 0, "+", ""),
                                       pctDiff, "%"),
                         y = diff),
                    nudge_y = ifelse(site_stats$diff > 0, 2, -2),
                    size = 4,
                    segment.size = 0.3) +
    coord_flip() +
    labs(
      title = paste0("Difference in mean ", ref_genus,
                     " rel. abundance vs ", ref_site, " (± SEM)"),
      x = NULL,
      y = "Difference in mean rel. abundance (%)"
    ) +
    theme_bw(base_size = 14) +
    theme(
      panel.grid.major.y = element_blank(),
      panel.grid.minor   = element_blank()
    )
  
  # Save outputs
  plots[[ref_genus]] <- p
  ttests[[ref_genus]] <- list(
    genus  = ref_genus,
    result = pairwise.t.test(df$relAbund, df$Site,
                             p.adjust.method = "BH",
                             pool.sd = FALSE)
  )
}


# 6) Look at t-test results (example)
ttests[["Apilactobacillus"]]
ttests[["Brevundimonas"]]
ttests[["Candidatus Rhabdochlamydia"]]
ttests[["Catellicoccus"]]
ttests[["Commensalibacter"]]
ttests[["Dysgonomonas"]]
ttests[["Enterococcus"]]
ttests[["Fructobacillus"]]
ttests[["Klebsiella"]]
ttests[["Leuconostoc"]]
ttests[["Morganella"]]
ttests[["Paenibacillus"]]
ttests[["Providencia"]]
ttests[["Rickettsiella"]]
ttests[["Serratia"]]
ttests[["Stenotrophomonas"]]
ttests[["Weissella"]]
```

```{r}
## ────────────────────────────────────────────────────────────────
## BLOCK 1 — DATA PREP (GENUS LEVEL)
## Inputs expected in environment:
##   dat: phyloseq object with counts + taxonomy (has Genus)
##   ref_site: character (e.g., "DWTP")
##   genera_of_interest: character vector of genera to evaluate
## ────────────────────────────────────────────────────────────────

suppressPackageStartupMessages({
  library(phyloseq)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(ggrepel)
  library(rstatix)
})

# Option: drop sites that are 100% zeros for a given genus
drop_all_zero_sites <- TRUE
label_nudge <- 2  # offset for % labels on plots

# 1) Agglomerate to Genus
ps_genus <- tax_glom(dat, taxrank = "Genus")

# 2) Long data + per-sample totals
df_all_genus <- psmelt(ps_genus) %>%
  group_by(Sample) %>%
  mutate(sample_total = sum(Abundance)) %>%
  ungroup()

# 3) Initialize containers for Block 2
plots_genus     <- list()  # per-genus ggplot objects
tests_genus     <- list()  # per-genus stats results
summaries_genus <- list()  # tidy-ish posthoc tables per genus
```
                                     
```{r}
## ────────────────────────────────────────────────────────────────
## BLOCK 2 — RUN TESTS (GENUS LEVEL)
## For each genus: per-sample relative abundance ~ Site
## Primary: one-way ANOVA + TukeyHSD
## Fallback: Kruskal–Wallis + Dunn (BH)
## ────────────────────────────────────────────────────────────────

for (ref_genus in genera_of_interest) {

  # Per-sample relative abundance
  df <- df_all_genus %>%
    dplyr::filter(Genus == ref_genus) %>%
    dplyr::group_by(Site, Sample) %>%
    dplyr::summarise(relAbund = sum(Abundance) / unique(sample_total),
                     .groups = "drop")

  # Optionally drop sites with all-zero relAbund
  if (drop_all_zero_sites) {
    site_nonzero <- df %>%
      dplyr::group_by(Site) %>%
      dplyr::summarise(all_zero = all(relAbund == 0), .groups = "drop") %>%
      dplyr::filter(!all_zero) %>%
      dplyr::pull(Site)
    df <- df %>% dplyr::filter(Site %in% site_nonzero)
  }

  # Guard: need ≥2 sites
  if (dplyr::n_distinct(df$Site) < 2 || nrow(df) < 3) {
    next
  }

  # Ensure Site is a factor
  site_levels <- c(ref_site, sort(unique(df$Site[df$Site != ref_site])))
  df <- df %>% dplyr::mutate(Site = factor(Site, levels = site_levels))

  # Track whether reference site is present
  can_plot_vs_ref <- ref_site %in% df$Site

  # ── Assumptions ──
  by_site <- df %>%
    dplyr::group_by(Site) %>%
    dplyr::summarise(n = dplyr::n(), sd_rel = sd(relAbund), .groups = "drop")

  force_nonparam <- any(by_site$n < 3 | by_site$sd_rel == 0, na.rm = TRUE)

  shapiro_by_site <- df %>%
    dplyr::group_by(Site) %>%
    dplyr::summarise(
      shapiro_p = if (n() >= 3 && sd(relAbund) > 0) {
        stats::shapiro.test(relAbund)$p.value
      } else {
        NA_real_
      },
      .groups = "drop"
    )

  lev_p <- tryCatch(
    rstatix::levene_test(df, relAbund ~ Site)$p,
    error = function(e) NA_real_
  )

  normal_ok <- !force_nonparam && all(shapiro_by_site$shapiro_p > 0.05, na.rm = TRUE)
  homo_ok   <- !is.na(lev_p) && lev_p > 0.05

  # ── Tests ──
  if (normal_ok && homo_ok) {
    aov_model <- aov(relAbund ~ Site, data = df)
    aov_sum   <- summary(aov_model)
    tuk       <- TukeyHSD(aov_model)

    tests_genus[[ref_genus]] <- list(
      genus       = ref_genus,
      method      = "ANOVA + TukeyHSD",
      assumptions = list(by_site = by_site, shapiro = shapiro_by_site, levene_p = lev_p),
      anova       = aov_sum,
      posthoc     = tuk
    )

    tk_df <- as.data.frame(tuk$Site)
    tk_df$comparison <- rownames(tk_df)
    summaries_genus[[ref_genus]] <- tk_df %>%
      dplyr::select(comparison, diff = diff, lwr = lwr, upr = upr, p_adj = `p adj`) %>%
      dplyr::mutate(genus = ref_genus, method = "TukeyHSD")

  } else {
    kw   <- rstatix::kruskal_test(df, relAbund ~ Site)
    dunn <- rstatix::dunn_test(df, relAbund ~ Site, p.adjust.method = "BH")

    tests_genus[[ref_genus]] <- list(
      genus       = ref_genus,
      method      = "Kruskal–Wallis + Dunn (BH)",
      assumptions = list(by_site = by_site, shapiro = shapiro_by_site, levene_p = lev_p),
      kruskal     = kw,
      posthoc     = dunn
    )

    summaries_genus[[ref_genus]] <- dunn %>%
      dplyr::select(group1, group2, p.adj) %>%
      dplyr::rename(comparison_paired_groups = group1,
                    comparison_against       = group2,
                    p_adj                    = p.adj) %>%
      dplyr::mutate(genus = ref_genus, method = "Dunn (BH)")
  }

  # ── Plot (only if reference site present) ──
  if (can_plot_vs_ref) {
    site_stats <- df %>%
      dplyr::group_by(Site) %>%
      dplyr::summarise(
        meanRA = mean(relAbund) * 100,
        semRA  = sd(relAbund) / sqrt(dplyr::n()) * 100,
        n      = dplyr::n(),
        .groups = "drop"
      )

    ref_mean <- site_stats %>% dplyr::filter(Site == ref_site) %>% dplyr::pull(meanRA)
    site_stats <- site_stats %>%
      dplyr::mutate(
        diff    = meanRA - ref_mean,
        pctDiff = round(ifelse(ref_mean == 0, NA_real_, diff / ref_mean * 100), 1)
      )

    plots_genus[[ref_genus]] <- ggplot(site_stats, aes(x = Site, y = diff)) +
      geom_hline(yintercept = 0, linetype = "dashed") +
      geom_pointrange(aes(ymin = diff - semRA, ymax = diff + semRA), size = 0.8) +
      geom_text_repel(
        aes(label = ifelse(is.na(pctDiff), "NA", paste0(ifelse(pctDiff > 0, "+", ""), pctDiff, "%")),
            y = diff),
        nudge_y = ifelse(site_stats$diff > 0, label_nudge, -label_nudge),
        size = 4, segment.size = 0.3
      ) +
      coord_flip() +
      labs(
        title = paste0("Difference in mean ", ref_genus,
                       " relative abundance vs ", ref_site, " (± SEM)"),
        x = NULL,
        y = "Difference in mean relative abundance (%)"
      ) +
      theme_bw(base_size = 14) +
      theme(panel.grid.major.y = element_blank(),
            panel.grid.minor   = element_blank())
  } else {
    plots_genus[[ref_genus]] <- NULL
  }
}
```    

```{r}
## ────────────────────────────────────────────────────────────────
## BLOCK 3 — GENERA PAIRWISE P-VALUES
## Produces a tidy table of adjusted p-values (with stars)
## Also gives a filtered table of significant results only
## ────────────────────────────────────────────────────────────────

.star <- function(p) ifelse(is.na(p), "",
                      ifelse(p < 0.001, "***",
                      ifelse(p < 0.01,  "**",
                      ifelse(p < 0.05,  "*", ""))))

pairwise_pvals_genus <- bind_rows(lapply(names(tests_genus), function(gn) {
  x <- tests_genus[[gn]]
  if (is.null(x$posthoc)) return(NULL)

  if (identical(x$method, "ANOVA + TukeyHSD")) {
    tk <- as.data.frame(x$posthoc$Site)
    tk$comparison <- rownames(tk)
    tk %>%
      transmute(
        genus      = gn,
        method     = "TukeyHSD",
        comparison = comparison,
        p_adj      = `p adj`,
        sig        = .star(p_adj)
      )
  } else {
    dn <- x$posthoc
    dn %>%
      transmute(
        genus      = gn,
        method     = "Dunn (BH)",
        comparison = paste0(group1, " - ", group2),
        p_adj      = p.adj,
        sig        = .star(p.adj)
      )
  }
}), .id = NULL) %>%
  arrange(genus, p_adj) %>%
  mutate(p_adj = signif(p_adj, 3))

## === Significant only (p < 0.05) ===
sig_pairwise_genus <- pairwise_pvals_genus %>%
  filter(!is.na(p_adj) & p_adj < 0.05)

## === Usage examples ===
# View all results
pairwise_pvals_genus

# View only significant pairs
sig_pairwise_genus
```

```{r}
library(phyloseq)
library(ggplot2)
library(dplyr)

# Extract the data as a data frame from your phyloseq object
ps_df <- psmelt(dat.top20)

table(ps_df$Phylum_new)
ps_df_full <- psmelt(dat)  # using the full dataset rather than dat.top20


# Recode the "Phylum" variable into a new variable "Phylum_new" based on your rules:
ps_df_full <- ps_df_full %>%
  mutate(Phylum_new = case_when(
    # Big 4 with additional names in parentheses:
    Phylum %in% "Actinomycetota"  ~ "Actinomycetota (Actinobacteria)",
    Phylum %in% "Bacillota"       ~ "Bacillota (Firmicutes)",
    Phylum %in% "Bacteroidota"    ~ "Bacteroidota (Bacteroidetes)",
    Phylum %in% "Pseudomonadota"  ~ "Pseudomonadota (Proteobacteria)",
    # Also keep Chlamydiota as its own group:
    Phylum %in% "Chlamydiota"     ~ "Chlamydiota",
    # Replace NA or "NA" with "Unidentifiable"
    is.na(Phylum) | Phylum == "NA" ~ "Unidentifiable",
    # All others fall into "Other"
    TRUE                         ~ "Other"
  ))

# Now create the plot. We use position = "fill" so the y-axis scales from 0 to 1.
tax_plot7 <- ggplot(ps_df_full, aes(x = Sample, y = Abundance, fill = Phylum_new)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_wrap(~Site, scales = "free_x") +
  scale_fill_manual(values = colours.un) +
  labs(title = "Top Phyla", 
       y = "Relative Abundance",
       fill = "Phylum") +
  guides(fill = guide_legend(nrow = 30)) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x   = element_text(angle = 270, hjust = 0, vjust = 0.5, size = 8),
    legend.position = "right",
    legend.key.size = unit(0.3, "cm")
  )

# Print the plot
print(tax_plot7)
```

```{r}
library(phyloseq)
library(ggplot2)
library(dplyr)
library(ggtext)   # <- added

# Extract the data as a data frame from your phyloseq object
ps_df <- psmelt(dat.top20)

table(ps_df$Genus_new)
ps_df_full <- psmelt(dat)  # using the full dataset rather than dat.top20

# Recode the "Genus" variable into a new variable "Genus_new" based on your rules:
ps_df_full <- ps_df_full %>%
  mutate(
    Genus_new = case_when(
      Genus %in% "Apilactobacillus"  ~ "Apilactobacillus (Firmicutes)",
      Genus %in% "Catellicoccus"     ~ "Catellicoccus (Firmicutes)",
      Genus %in% "Enterococcus"      ~ "Enterococcus (Firmicutes)",
      Genus %in% "Fructobacillus"    ~ "Fructobacillus (Firmicutes)",
      Genus %in% "Leuconostoc"       ~ "Leuconostoc (Firmicutes)",
      Genus %in% "Paenibacillus"     ~ "Paenibacillus (Firmicutes)",
      Genus %in% "Weissella"         ~ "Weissella (Firmicutes)",
      Genus %in% "Dysgonomonas"      ~ "Dysgonomonas (Bacteroidetes)",
      Genus %in% "Brevundimonas"     ~ "Brevundimonas (Proteobacteria)",
      Genus %in% "Klebsiella"        ~ "Klebsiella (Proteobacteria)",
      Genus %in% "Commensalibacter"  ~ "Commensalibacter (Proteobacteria)",
      Genus %in% "Morganella"        ~ "Morganella (Proteobacteria)",
      Genus %in% "Providencia"       ~ "Providencia (Proteobacteria)",
      Genus %in% "Rickettsiella"     ~ "Rickettsiella (Proteobacteria)",
      Genus %in% "Serratia"          ~ "Serratia (Proteobacteria)",
      Genus %in% "Stenotrophomonas"  ~ "Stenotrophomonas (Proteobacteria)",
      Genus %in% "Candidatus Rhabdochlamydia" ~ "Candidatus Rhabdochlamydia",
      is.na(Genus) | Genus == "NA"   ~ "Unidentifiable",
      TRUE                           ~ "Other"
    )
  ) %>%
  # talicize ONLY the genus portion before the first space/parenthesis
  mutate(
    Genus_new = ifelse(
      Genus_new %in% c("Other", "Unidentifiable"),
      Genus_new,
      sub("^([^ ]+)", "<i>\\1</i>", Genus_new)  # italicize first word only
    )
  )

# Plot
tax_plot7 <- ggplot(ps_df_full, aes(x = Sample, y = Abundance, fill = Genus_new)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_wrap(~Site, scales = "free_x") +
  scale_fill_manual(values = colorRampPalette(colours.un)(length(unique(ps_df_full$Genus_new)))) +
  labs(title = "Top Genus", 
       y = "Relative Abundance",
       fill = "Genus") +
  guides(fill = guide_legend(nrow = 30)) +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x   = element_text(angle = 270, hjust = 0, vjust = 0.5, size = 8),
    legend.position = "right",
    legend.key.size = unit(0.3, "cm"),
    legend.text = element_markdown()  # <- enables italics in legend
  )

# Print the plot
print(tax_plot7)
```

```{r}
##Abundance by phyla metadata

library(dplyr)
library(tidyr)

# Extract numeric values from Sample and order them correctly
percentages <- percentages %>%
  mutate(Sample_num = as.numeric(gsub("EC", "", Sample))) %>%
  arrange(Sample_num) %>%
  select(-Sample_num)  # Remove temporary numeric column

# Convert Sample to a factor in correct order
percentages$Sample <- factor(percentages$Sample, levels = unique(percentages$Sample))

# Summarize and reshape data
df_wide <- percentages %>%
  group_by(Sample, Phylum) %>% 
  summarise(Abundance = sum(Abundance, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = Phylum, values_from = Abundance, values_fill = 0)

# View the transformed data
print(df_wide)

# Save to CSV if needed
write.csv(df_wide, ##(Phyla abundance CSV), row.names = FALSE)

```

```{r}
##Abundance by genus metadata

library(dplyr)
library(tidyr)

# Extract numeric values from Sample and order them correctly
percentages <- percentages %>%
  mutate(Sample_num = as.numeric(gsub("EC", "", Sample))) %>%
  arrange(Sample_num) %>%
  select(-Sample_num)  # Remove temporary numeric column

# Convert Sample to a factor in correct order
percentages$Sample <- factor(percentages$Sample, levels = unique(percentages$Sample))

# Summarize and reshape data
df_wide <- percentages %>%
  group_by(Sample, Genus) %>% 
  summarise(Abundance = sum(Abundance, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = Genus, values_from = Abundance, values_fill = 0)

# View the transformed data
print(df_wide)

# Save to CSV if needed
write.csv(df_wide, ##(Genus abundance CSV), row.names = FALSE)
```                                     

```{r}
## ── Phylum counts + “most abundant phyla (mean ± SE%)” sentence ─────────────
library(phyloseq)
library(dplyr)
library(tidyr)
library(stringr)
library(tibble)
library(glue)

# 0) Helper
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

# 1) Start from your host-filtered object
ps0 <- dat_lessHOST

# 2) Collapse to Phylum and convert to relative abundance per sample
ps_phy   <- tax_glom(ps0, taxrank = "Phylum", NArm = FALSE)
ps_phy_r <- transform_sample_counts(ps_phy, function(x) x / sum(x))

# 3) Extract abundance matrix and taxonomy
A <- as(otu_table(ps_phy_r), "matrix")
if (!taxa_are_rows(ps_phy_r)) A <- t(A)
TX <- as(tax_table(ps_phy_r), "matrix")[rownames(A), , drop = FALSE]

df <- as_tibble(A, rownames = "ASV") |>
  pivot_longer(-ASV, names_to = "SampleID", values_to = "RelAbund") |>
  left_join(as_tibble(TX, rownames = "ASV") |> select(ASV, Phylum),
            by = "ASV") |>
  mutate(
    Phylum = case_when(
      is.na(Phylum) | Phylum %in% c("", "NA") ~ "Unclassified",
      TRUE                                    ~ Phylum
    )
  )

# 4) (Optional) Recode to legacy/common names used elsewhere in your doc
recode_to_legacy <- TRUE
if (recode_to_legacy) {
  df <- df |>
    mutate(Phylum = case_when(
      Phylum == "Actinomycetota"  ~ "Actinomycetota (Actinobacteria)",
      Phylum == "Bacillota"       ~ "Bacillota (Firmicutes)",
      Phylum == "Bacteroidota"    ~ "Bacteroidota (Bacteroidetes)",
      Phylum == "Pseudomonadota"  ~ "Pseudomonadota (Proteobacteria)",
      TRUE                        ~ Phylum
    ))
}

# 5) Summary stats by phylum (in percent)
phylum_stats <- df |>
  group_by(Phylum) |>
  summarise(
    n_samples = n_distinct(SampleID),
    mean_pct  = mean(RelAbund, na.rm = TRUE) * 100,
    se_pct    = se(RelAbund) * 100,
    .groups   = "drop"
  ) |>
  arrange(desc(mean_pct))

# 6) Totals
n_phyla_incl_unc <- n_distinct(phylum_stats$Phylum)
n_phyla_excl_unc <- phylum_stats |>
  filter(!Phylum %in% c("Unclassified", "Unidentifiable")) |>
  summarise(n = n_distinct(Phylum)) |>
  pull(n)

# 7) Pick top-k phyla for the sentence
k <- 10
top_tbl <- phylum_stats |>
  filter(!Phylum %in% c("Unclassified", "Unidentifiable")) |>
  slice_head(n = k)

# 8) Build sentences
fmt <- function(m, s) sprintf("%.1f \u00B1 %.1f", m, s)
top_phrase <- paste0(
  top_tbl$Phylum, " (", mapply(fmt, top_tbl$mean_pct, top_tbl$se_pct), "%)"
) |> paste(collapse = ", ")

cat(glue(
  "Across all samples, there were {n_phyla_incl_unc} bacterial phyla ",
  "(or {n_phyla_excl_unc} excluding 'Unclassified').\n"
))

cat(glue(
  "The most abundant phyla identified were {top_phrase}.\n"
))
```

```{r}
## ── Top 5 phyla per site → prose sentences (mean ± SE %) ─────────────────────
library(phyloseq)
library(dplyr)
library(tidyr)
library(stringr)
library(tibble)

# Standard error helper
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

# Nice join: "A, B, C, and D"
join_with_and <- function(x) {
  x <- as.character(x)
  n <- length(x)
  if (n <= 1) return(paste0(x, collapse = ""))
  paste0(paste0(x[1:(n-1)], collapse = ", "), ", and ", x[n])
}

# Start from your host-filtered phyloseq object
ps0 <- dat_lessHOST

# Collapse to Phylum, convert to per-sample relative abundance
ps_phy   <- tax_glom(ps0, taxrank = "Phylum", NArm = FALSE)
ps_phy_r <- transform_sample_counts(ps_phy, function(x) x / sum(x))

# Long format with Site/Phylum/RelAbund
df <- psmelt(ps_phy_r) %>%
  mutate(
    Phylum = ifelse(is.na(Phylum) | Phylum %in% c("", "NA"),
                    "Unclassified", Phylum)
  ) %>%
  select(Site, Sample, Phylum, RelAbund = Abundance)

# (Optional) Recode to legacy/common names used elsewhere
recode_to_legacy <- TRUE
if (recode_to_legacy) {
  df <- df %>%
    mutate(Phylum = case_when(
      Phylum == "Actinomycetota" ~ "Actinomycetota (Actinobacteria)",
      Phylum == "Bacillota"      ~ "Bacillota (Firmicutes)",
      Phylum == "Bacteroidota"   ~ "Bacteroidota (Bacteroidetes)",
      Phylum == "Pseudomonadota" ~ "Pseudomonadota (Proteobacteria)",
      TRUE                       ~ Phylum
    ))
}

# Per-site × phylum mean ± SE (%)
site_phylum_stats <- df %>%
  group_by(Site, Phylum) %>%
  summarise(
    n_samples = n_distinct(Sample),
    mean_pct  = mean(RelAbund, na.rm = TRUE) * 100,
    se_pct    = se(RelAbund) * 100,
    .groups   = "drop"
  )

# Keep the top 5 phyla per site (by mean %)
top5_by_site <- site_phylum_stats %>%
  group_by(Site) %>%
  slice_max(order_by = mean_pct, n = 5, with_ties = FALSE) %>%
  arrange(Site, desc(mean_pct)) %>%
  ungroup() %>%
  # round for clean prose
  mutate(
    mean_pct = round(mean_pct, 2),   # keep 2 dp internally…
    se_pct   = round(se_pct,   2),
    # …but print as 1 dp in the phrase
    phrase   = sprintf("%s (%.1f \u00B1 %.1f%%)", Phylum, mean_pct, se_pct)
  )

# Build one sentence per site
sentences <- top5_by_site %>%
  group_by(Site) %>%
  summarise(
    sentence = {
      first_item <- phrase[1]
      rest_items <- phrase[-1]
      paste0(
        "At ", unique(Site), ", the dominant phylum was ",
        first_item,
        if (length(rest_items) > 0)
          paste0(" followed by ", join_with_and(rest_items))
        else "",
        "."
      )
    },
    .groups = "drop"
  )

# Print each site’s sentence on its own line (or use "\n\n" for blank lines)
cat(paste(sentences$sentence, collapse = "\n\n"))
```

```{r}
## ── PERMANOVA at the Phylum level ────────────────────────────────────────────
library(phyloseq)
library(vegan)
library(dplyr)

# 0) Choose your phyloseq object
ps <- dat_lessHOST   # or dat_r, etc.

# 1) Agglomerate to Phylum
ps_phy <- tax_glom(ps, taxrank = "Phylum", NArm = FALSE)

# 2) Make per-sample relative abundance (so library size doesn't dominate)
ps_phy_rel <- transform_sample_counts(ps_phy, function(x) x / sum(x))

# 3) Community matrix (samples x phyla) + metadata
X <- as(otu_table(ps_phy_rel), "matrix")
if (taxa_are_rows(ps_phy_rel)) X <- t(X)
meta <- as(sample_data(ps_phy_rel), "data.frame")

# 4) Align rows; drop all-zero samples
common <- intersect(rownames(X), rownames(meta))
X   <- X[common, , drop = FALSE]
meta <- meta[common, , drop = FALSE]
keep <- rowSums(X) > 0
X    <- X[keep, , drop = FALSE]
meta <- meta[keep, , drop = FALSE]

# 5) Grouping factor
stopifnot("Site" %in% names(meta))
meta$Site <- droplevels(factor(meta$Site))

# If any Site has <2 samples, drop it for pairwise testing
bad <- names(which(table(meta$Site) < 2))
if (length(bad)) {
  message("Dropping groups with <2 samples: ", paste(bad, collapse = ", "))
  keep2 <- !(meta$Site %in% bad)
  X    <- X[keep2, , drop = FALSE]
  meta <- meta[keep2, , drop = FALSE]
  meta$Site <- droplevels(meta$Site)
}

# (Optional) decide what to do with Unclassified phyla:
# If you want to keep them (recommended for honesty), do nothing.
# If you want to drop them from the matrix:
# phyla <- colnames(X)
# to_drop <- grepl("Unclassified|Unassigned|NA", phyla, ignore.case = TRUE)
# X <- X[, !to_drop, drop = FALSE]

# 6) Distance and global PERMANOVA
set.seed(42)
perm_n <- 999
bc_phy <- vegdist(X, method = "bray")

a2_phy <- adonis2(bc_phy ~ Site, data = meta, permutations = perm_n, by = "terms")
print(a2_phy)
# → Report pseudo-F, R2, p, permutations from this table.

# 7) Pairwise PERMANOVA at Phylum level (PRIMER-style comparisons)
# Install the helper once if needed:
# install.packages("remotes")
# remotes::install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")

library(pairwiseAdonis)

# Use the distance object + formula (most robust)
set.seed(42)
pw_phy <- pairwise.adonis2(bc_phy ~ Site, data = meta, permutations = perm_n)
print(pw_phy)

# start from phylum-level relative abundance object
ps_phy <- tax_glom(dat_lessHOST, taxrank = "Phylum", NArm = FALSE)
ps_phy_rel <- transform_sample_counts(ps_phy, function(x) x / sum(x))

df <- psmelt(ps_phy_rel) %>%
  select(Site, Sample, Phylum, Abundance) %>%
  mutate(
    Group = ifelse(Site %in% c("BWTP", "BRL", "DWTP", "WBS"),
                   "Waste", "Rural")
  )

# summarise mean ± SE per Group × Phylum
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

phylum_summary <- df %>%
  group_by(Group, Phylum) %>%
  summarise(
    mean_pct = mean(Abundance, na.rm = TRUE) * 100,
    se_pct   = se(Abundance) * 100,
    .groups  = "drop"
  ) %>%
  arrange(Group, desc(mean_pct))

phylum_summary
```

```{r}
## ── PERMANOVA: Rural vs Waste at Phylum level ────────────────────────────────
library(phyloseq)
library(vegan)
library(dplyr)

# 1) Agglomerate to Phylum
ps_phy <- tax_glom(dat_lessHOST, taxrank = "Phylum", NArm = FALSE)

# 2) Relative abundance per sample
ps_phy_rel <- transform_sample_counts(ps_phy, function(x) x / sum(x))

# 3) Extract data
X <- as(otu_table(ps_phy_rel), "matrix")
if (taxa_are_rows(ps_phy_rel)) X <- t(X)
meta <- as(sample_data(ps_phy_rel), "data.frame")

# 4) Define grouping: Rural vs Waste
meta$Group <- ifelse(meta$Site %in% c("MF","MD"), "Rural", "Waste")
meta$Group <- factor(meta$Group)

# 5) Align sample names
common <- intersect(rownames(X), rownames(meta))
X   <- X[common, , drop = FALSE]
meta <- meta[common, , drop = FALSE]

# 6) Drop all-zero samples
keep <- rowSums(X) > 0
X    <- X[keep, , drop = FALSE]
meta <- meta[keep, , drop = FALSE]

# 7) Distance
bc_phy <- vegdist(X, method = "bray")

# 8) Global PERMANOVA
set.seed(42)
perm_n <- 999
adonis_group <- adonis2(bc_phy ~ Group, data = meta,
                        permutations = perm_n, by = "terms")
print(adonis_group)

# 9) Dispersion check (PERMDISP) to ensure differences aren’t due to heterogeneity
bd <- betadisper(bc_phy, meta$Group)
anova(bd)        # ANOVA test on dispersion
permutest(bd)    # permutation test

```

```{r}
suppressPackageStartupMessages({
  library(phyloseq)
  library(dplyr)
  library(stringr)
})

# 1) Collapse to Genus
ps_genus <- tax_glom(dat, taxrank = "Genus")

# 2) Per-sample relative abundance (%)
df_genus <- psmelt(ps_genus) %>%
  group_by(Sample) %>%
  mutate(relAbund = 100 * Abundance / sum(Abundance)) %>%
  ungroup()

# 3) Summarize across samples (mean ± SE) at Genus
genus_summary <- df_genus %>%
  group_by(Genus) %>%
  summarise(
    mean_relAbund = mean(relAbund, na.rm = TRUE),
    se_relAbund   = sd(relAbund, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# 4) Exclude unclassified/uncultured/unassigned and NA genus labels
is_bad <- function(x) {
  ifelse(is.na(x), TRUE, str_detect(x, regex("unclassified|uncultured|unassigned|na", ignore_case = TRUE)))
}
genus_clean <- genus_summary %>% filter(!is_bad(Genus))

# 5) Count total genera and pick Top 10
n_genera <- nrow(genus_clean)
top_n <- 10
top_genera <- genus_clean %>%
  arrange(desc(mean_relAbund)) %>%
  slice_head(n = min(top_n, n_genera)) %>%
  mutate(
    mean_txt = sprintf("%.1f", mean_relAbund),
    se_txt   = sprintf("%.1f", se_relAbund),
    piece    = paste0(Genus, " (", mean_txt, " \u00B1 ", se_txt, "%)")
  )

# 6) Build the narrative sentence
sentence <- paste0(
  "Across all fecal samples, there were ", n_genera, " bacterial genera. ",
  "The most abundant genera identified were ",
  paste(top_genera$piece, collapse = ", "),
  "."
)

cat(sentence, "\n")
```

```{r}
## ── PERMANOVA at the Genus level ───────────────────────────────────────────────
library(phyloseq)
library(vegan)
library(dplyr)

# 0) Choose your phyloseq object
ps <- dat_lessHOST   # or dat_r, etc.

# 1) Agglomerate to Genus
ps_gen <- tax_glom(ps, taxrank = "Genus", NArm = FALSE)

# 2) Make per-sample relative abundance (so library size doesn't dominate)
ps_gen_rel <- transform_sample_counts(ps_gen, function(x) x / sum(x))

# 3) Community matrix (samples x genera) + metadata
X <- as(otu_table(ps_gen_rel), "matrix")
if (taxa_are_rows(ps_gen_rel)) X <- t(X)
meta <- as(sample_data(ps_gen_rel), "data.frame")

# 4) Align rows; drop all-zero samples
common <- intersect(rownames(X), rownames(meta))
X    <- X[common, , drop = FALSE]
meta <- meta[common, , drop = FALSE]
keep <- rowSums(X) > 0
X    <- X[keep, , drop = FALSE]
meta <- meta[keep, , drop = FALSE]

# 5) Grouping factor
stopifnot("Site" %in% names(meta))
meta$Site <- droplevels(factor(meta$Site))

# If any Site has <2 samples, drop it for pairwise testing
bad <- names(which(table(meta$Site) < 2))
if (length(bad)) {
  message("Dropping groups with <2 samples: ", paste(bad, collapse = ", "))
  keep2 <- !(meta$Site %in% bad)
  X    <- X[keep2, , drop = FALSE]
  meta <- meta[keep2, , drop = FALSE]
  meta$Site <- droplevels(meta$Site)
}

# (Optional) decide what to do with Unclassified genera:
# If you want to keep them (recommended for transparency), do nothing.
# If you want to drop them from the matrix:
# genera <- colnames(X)
# to_drop <- grepl("Unclassified|Unassigned|NA|uncultured", genera, ignore.case = TRUE)
# X <- X[, !to_drop, drop = FALSE]

# 6) Distance and global PERMANOVA
set.seed(42)
perm_n <- 999
bc_gen <- vegdist(X, method = "bray")

a2_gen <- adonis2(bc_gen ~ Site, data = meta, permutations = perm_n, by = "terms")
print(a2_gen)
# → Report pseudo-F, R2, p, permutations from this table.

# 7) Pairwise PERMANOVA at Genus level (PRIMER-style comparisons)
# Install the helper once if needed:
# install.packages("remotes")
# remotes::install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")

library(pairwiseAdonis)

# Use the distance object + formula (robust to factor coding)
set.seed(42)
pw_gen <- pairwise.adonis2(bc_gen ~ Site, data = meta, permutations = perm_n)
print(pw_gen)

```

```{r}
## ── Top 10 genera per site → prose sentences (mean ± SE %) ────────────────────
library(phyloseq)
library(dplyr)
library(tidyr)
library(stringr)
library(tibble)

# ---- Helpers -----------------------------------------------------------------
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

join_with_and <- function(x) {
  x <- as.character(x); n <- length(x)
  if (n <= 1) return(paste0(x, collapse = ""))
  paste0(paste0(x[1:(n-1)], collapse = ", "), ", and ", x[n])
}

# ---- Settings ----------------------------------------------------------------
ps0 <- dat_lessHOST            # your host-filtered phyloseq object
group_var <- "Site"            # grouping column in sample_data
top_n <- 10                    # number of genera to report per site
exclude_unclassified <- TRUE   # drop "unclassified/uncultured/unassigned" genera
include_parent_phylum <- TRUE  # append parent phylum to each genus in prose
italicize <- TRUE              # italicize Genus (and Phylum, if appended)

# ---- Collapse to Genus and compute per-sample relative abundance --------------
ps_gen   <- tax_glom(ps0, taxrank = "Genus", NArm = FALSE)
ps_gen_r <- transform_sample_counts(ps_gen, function(x) x / sum(x))

# Long format with Site / Sample / Genus / Phylum / RelAbund
df <- psmelt(ps_gen_r) %>%
  mutate(
    Genus  = ifelse(is.na(Genus)  | Genus  %in% c("", "NA"), "Unclassified", Genus),
    Phylum = ifelse(is.na(Phylum) | Phylum %in% c("", "NA"), "Unclassified", Phylum)
  ) %>%
  select(!!sym(group_var), Sample, Genus, Phylum, RelAbund = Abundance)

# Optional: drop unclassified/uncultured labels (genus only)
if (exclude_unclassified) {
  df <- df %>%
    filter(!str_detect(Genus, regex("unclassified|uncultured|unassigned|^NA$", ignore_case = TRUE)))
}

# Optional: recode phylum names to include legacy/common equivalents
if (include_parent_phylum) {
  df <- df %>%
    mutate(Phylum = case_when(
      Phylum == "Actinomycetota" ~ "Actinomycetota (Actinobacteria)",
      Phylum == "Bacillota"      ~ "Bacillota (Firmicutes)",
      Phylum == "Bacteroidota"   ~ "Bacteroidota (Bacteroidetes)",
      Phylum == "Pseudomonadota" ~ "Pseudomonadota (Proteobacteria)",
      TRUE                       ~ Phylum
    ))
}

# ---- Per-site × genus mean ± SE (%) ------------------------------------------
site_genus_stats <- df %>%
  group_by(.data[[group_var]], Genus, Phylum) %>%
  summarise(
    n_samples = n_distinct(Sample),
    mean_pct  = mean(RelAbund, na.rm = TRUE) * 100,
    se_pct    = se(RelAbund) * 100,
    .groups   = "drop"
  )

# Keep the top N genera per site (by mean %)
topN_by_site <- site_genus_stats %>%
  group_by(.data[[group_var]]) %>%
  slice_max(order_by = mean_pct, n = top_n, with_ties = FALSE) %>%
  arrange(.data[[group_var]], desc(mean_pct)) %>%
  ungroup()

# Format phrases (mean ± SE %) and optional italics/parent phylum
fmt_name <- function(x, do_it = italicize) if (do_it) paste0("*", x, "*") else x

topN_by_site <- topN_by_site %>%
  mutate(
    mean_pct_r = round(mean_pct, 1),
    se_pct_r   = round(se_pct,   1),
    genus_fmt  = fmt_name(Genus, italicize),
    phylum_fmt = if (include_parent_phylum) fmt_name(Phylum, italicize) else NA_character_,
    phrase     = if (include_parent_phylum)
                   sprintf("%s (%.1f \u00B1 %.1f%%; %s)", genus_fmt, mean_pct_r, se_pct_r, phylum_fmt)
                 else
                   sprintf("%s (%.1f \u00B1 %.1f%%)",      genus_fmt, mean_pct_r, se_pct_r)
  )

# ---- Build one sentence per site ---------------------------------------------
sentences <- topN_by_site %>%
  group_by(.data[[group_var]]) %>%
  summarise(
    sentence = {
      first_item <- phrase[1]
      rest_items <- phrase[-1]
      paste0(
        "At ", unique(.data[[group_var]]),
        ", the dominant genera were ",
        first_item,
        if (length(rest_items) > 0) paste0(" followed by ", join_with_and(rest_items)) else "",
        "."
      )
    },
    .groups = "drop"
  )

# ---- Print sentences ----------------------------------------------------------
cat(paste(sentences$sentence, collapse = "\n\n"), "\n")
```

```{r}
library(phyloseq)
library(dplyr)
library(tidyr)

# start from phylum-level relative abundance object
ps_phy <- tax_glom(dat_lessHOST, taxrank = "Genus", NArm = FALSE)
ps_phy_rel <- transform_sample_counts(ps_phy, function(x) x / sum(x))

df <- psmelt(ps_phy_rel) %>%
  select(Site, Sample, Genus, Abundance) %>%
  mutate(
    Group = ifelse(Site %in% c("BWTP", "BRL", "DWTP", "WBS"),
                   "Waste", "Rural")
  )

# summarise mean ± SE per Group × Phylum
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

genus_summary <- df %>%
  group_by(Group, Genus) %>%
  summarise(
    mean_pct = mean(Abundance, na.rm = TRUE) * 100,
    se_pct   = se(Abundance) * 100,
    .groups  = "drop"
  ) %>%
  arrange(Group, desc(mean_pct))

genus_summary
```

```{r}
## ── PERMANOVA: Rural vs Waste at Genus level ────────────────────────────────
library(phyloseq)
library(vegan)
library(dplyr)

# 1) Agglomerate to Phylum
ps_phy <- tax_glom(dat_lessHOST, taxrank = "Genus", NArm = FALSE)

# 2) Relative abundance per sample
ps_phy_rel <- transform_sample_counts(ps_phy, function(x) x / sum(x))

# 3) Extract data
X <- as(otu_table(ps_phy_rel), "matrix")
if (taxa_are_rows(ps_phy_rel)) X <- t(X)
meta <- as(sample_data(ps_phy_rel), "data.frame")

# 4) Define grouping: Rural vs Waste
meta$Group <- ifelse(meta$Site %in% c("MF","MD"), "Rural", "Waste")
meta$Group <- factor(meta$Group)

# 5) Align sample names
common <- intersect(rownames(X), rownames(meta))
X   <- X[common, , drop = FALSE]
meta <- meta[common, , drop = FALSE]

# 6) Drop all-zero samples
keep <- rowSums(X) > 0
X    <- X[keep, , drop = FALSE]
meta <- meta[keep, , drop = FALSE]

# 7) Distance
bc_phy <- vegdist(X, method = "bray")

# 8) Global PERMANOVA
set.seed(42)
perm_n <- 999
adonis_group <- adonis2(bc_phy ~ Group, data = meta,
                        permutations = perm_n, by = "terms")
print(adonis_group)

# 9) Dispersion check (PERMDISP) to ensure differences aren’t due to heterogeneity
bd <- betadisper(bc_phy, meta$Group)
anova(bd)        # ANOVA test on dispersion
permutest(bd)    # permutation test
```

```{r}
## ── Alpha diversity (Shannon & Simpson) per site + ANOVA ─────────────────────
library(phyloseq)
library(vegan)
library(dplyr)
library(tibble)

# 1) Choose your phyloseq object
ps <- dat_lessHOST   # replace with your object

# 2) Compute alpha diversity per sample
alpha_df <- data.frame(
  SampleID = sample_names(ps),
  Site     = as.factor(sample_data(ps)$Site),
  Shannon  = diversity(t(otu_table(ps)), index = "shannon"),
  Simpson  = diversity(t(otu_table(ps)), index = "simpson")
)

# 3) Site-level summary (mean ± SE)
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))
alpha_summary <- alpha_df %>%
  group_by(Site) %>%
  summarise(
    n_samples = n(),
    Shannon_mean  = mean(Shannon, na.rm = TRUE),
    Shannon_se    = se(Shannon),
    Simpson_mean  = mean(Simpson, na.rm = TRUE),
    Simpson_se    = se(Simpson),
    .groups = "drop"
  )

# 4) One-way ANOVAs
anova_shannon <- aov(Shannon ~ Site, data = alpha_df)
anova_simpson <- aov(Simpson ~ Site, data = alpha_df)

# Print results
cat("\n=== Site-level diversity summary (mean ± SE) ===\n")
print(alpha_summary)

cat("\n=== ANOVA: Shannon diversity ~ Site ===\n")
print(summary(anova_shannon))

cat("\n=== ANOVA: Simpson diversity ~ Site ===\n")
print(summary(anova_simpson))
```

```{r}
## ── Alpha diversity (Shannon & Simpson) grouped by Rural vs Waste ─────────────
library(dplyr)

# starting point: alpha_df from before
# alpha_df has SampleID, Site, Shannon, Simpson

# 1) Add a "Group" column (Rural vs Waste)
# adjust mapping of Sites → Group as appropriate for your dataset
alpha_df <- alpha_df %>%
  mutate(Group = case_when(
    Site %in% c("MD", "WBS") ~ "Rural",     # reference sites
    Site %in% c("BWTP", "DWTP", "MF", "BRL") ~ "Waste",   # waste-influenced sites
    TRUE ~ NA_character_
  ))

alpha_df$Group <- factor(alpha_df$Group, levels = c("Rural", "Waste"))

# 2) Summarise mean ± SE by Group
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))
alpha_summary_group <- alpha_df %>%
  group_by(Group) %>%
  summarise(
    n_samples = n(),
    Shannon_mean  = mean(Shannon, na.rm = TRUE),
    Shannon_se    = se(Shannon),
    Simpson_mean  = mean(Simpson, na.rm = TRUE),
    Simpson_se    = se(Simpson),
    .groups = "drop"
  )

cat("\n=== Group-level summary (mean ± SE) ===\n")
print(alpha_summary_group)

# 3) One-way ANOVAs
anova_shannon_group <- aov(Shannon ~ Group, data = alpha_df)
anova_simpson_group <- aov(Simpson ~ Group, data = alpha_df)

cat("\n=== ANOVA: Shannon diversity ~ Group ===\n")
print(summary(anova_shannon_group))

cat("\n=== ANOVA: Simpson diversity ~ Group ===\n")
print(summary(anova_simpson_group))

# 4) Welch's t-tests (preferred for 2-group comparisons, no equal variance assumption)
t_shannon <- t.test(Shannon ~ Group, data = alpha_df, var.equal = FALSE)
t_simpson <- t.test(Simpson ~ Group, data = alpha_df, var.equal = FALSE)

cat("\n=== Welch's t-test: Shannon diversity (Rural vs Waste) ===\n")
print(t_shannon)

cat("\n=== Welch's t-test: Simpson diversity (Rural vs Waste) ===\n")
print(t_simpson)
```

```{r}
## ── Morphometrics: mean ± SEM per Site + Rural vs Waste + tests ─────────────
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(tibble)
})

# Helper: SEM
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

# 0) Ensure key morphometric columns are numeric (you already did these above)
#    Also catch "Hatching Success" if present (sanitized earlier -> Hatching.Success)
num_candidates <- c("Weight.mg","Wing.Chord.mm","Right.Tarsus.mm","X9th.Primary.mm",
                    "Clutch.Size","Box.Temperature","Hatching.Success")
for (cn in intersect(num_candidates, names(map_df))) {
  map_df[[cn]] <- suppressWarnings(as.numeric(map_df[[cn]]))
}

# 1) Define Rural vs Waste groups (Rural = MF, MD)
grp_df <- map_df %>%
  mutate(Group = case_when(
    Site %in% c("MF","MD") ~ "Rural",
    Site %in% c("BWTP","DWTP","BRL","WBS") ~ "Waste",
    TRUE ~ NA_character_
  ))

# 2) Auto-detect morphometric columns:
#    take all numeric columns except obvious IDs/factors
id_like <- c("NAME","Site","Group","SampleID","Sample","Nest","NestID","ID")
morpho_cols <- names(grp_df)[sapply(grp_df, is.numeric)]
morpho_cols <- setdiff(morpho_cols, id_like)

cat("Detected morphometric variables:\n")
print(morpho_cols)

# 3) Per-Site summary (mean ± SEM)
morpho_site <- grp_df %>%
  group_by(Site) %>%
  summarise(across(all_of(morpho_cols),
                   list(mean = ~mean(.x, na.rm = TRUE),
                        se   = ~se(.x)),
                   .names = "{.col}__{.fn}"),
            .groups = "drop") %>%
  pivot_longer(-Site, names_to = "var_stat", values_to = "value") %>%
  separate(var_stat, into = c("variable","stat"), sep = "__") %>%
  pivot_wider(names_from = stat, values_from = value) %>%
  mutate(`mean ± SEM` = sprintf("%.2f ± %.2f", mean, se)) %>%
  arrange(Site, variable)

cat("\n=== Morphometrics per Site (mean ± SEM) ===\n")
print(morpho_site %>% select(Site, variable, `mean ± SEM`))

# 4) Rural vs Waste summary (mean ± SEM)
morpho_group <- grp_df %>%
  filter(!is.na(Group)) %>%
  group_by(Group) %>%
  summarise(across(all_of(morpho_cols),
                   list(mean = ~mean(.x, na.rm = TRUE),
                        se   = ~se(.x)),
                   .names = "{.col}__{.fn}"),
            .groups = "drop") %>%
  pivot_longer(-Group, names_to = "var_stat", values_to = "value") %>%
  separate(var_stat, into = c("variable","stat"), sep = "__") %>%
  pivot_wider(names_from = stat, values_from = value) %>%
  mutate(`mean ± SEM` = sprintf("%.2f ± %.2f", mean, se)) %>%
  arrange(Group, variable)

cat("\n=== Morphometrics by Group (Rural vs Waste; mean ± SEM) ===\n")
print(morpho_group %>% select(Group, variable, `mean ± SEM`))

# 5) Stats: Welch t-tests + ANOVA for each morphometric (Rural vs Waste)
vars_to_test <- morpho_cols
ttest_tbl <- lapply(vars_to_test, function(v){
  dsub <- grp_df %>% select(Group, Site, all_of(v)) %>% filter(!is.na(Group))
  # need at least 1 non-NA in each group
  ok <- dsub %>% group_by(Group) %>% summarise(n_nonNA = sum(!is.na(.data[[v]])), .groups="drop")
  if (nrow(ok) < 2 || any(ok$n_nonNA == 0)) return(NULL)

  # Welch t-test (no equal-variance assumption)
  tt <- try(t.test(reformulate("Group", response = v), data = dsub, var.equal = FALSE),
            silent = TRUE)
  if (inherits(tt, "try-error")) return(NULL)

  # One-way ANOVA (equivalent with two groups; included for completeness)
  av <- try(summary(aov(reformulate("Group", response = v), data = dsub))[[1]],
            silent = TRUE)

  tibble(
    variable   = v,
    t          = unname(tt$statistic),
    df_t       = unname(tt$parameter),
    p_t        = unname(tt$p.value),
    mean_Rural = mean(dsub[[v]][dsub$Group=="Rural"], na.rm = TRUE),
    mean_Waste = mean(dsub[[v]][dsub$Group=="Waste"], na.rm = TRUE),
    F_anova    = if (!inherits(av, "try-error")) unname(av$`F value`[1]) else NA_real_,
    p_anova    = if (!inherits(av, "try-error")) unname(av$`Pr(>F)`[1]) else NA_real_
  )
})
ttest_tbl <- bind_rows(ttest_tbl)

if (nrow(ttest_tbl)) {
  cat("\n=== Rural vs Waste tests (per morphometric) ===\n")
  print(ttest_tbl %>%
          mutate(across(c(t, df_t, p_t, mean_Rural, mean_Waste, F_anova, p_anova),
                        ~round(.x, 4))))
} else {
  cat("\n(No variables had sufficient data for group-wise testing.)\n")
}
```

```{r}
## ── Morphometric summary with Clutch, Hatching, Fledging, BCI ─
suppressPackageStartupMessages(library(dplyr))

# Helper functions
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))
summarize_trait <- function(x, digits_mean = 1, digits_se = 1, digits_range = 1) {
  x <- suppressWarnings(as.numeric(x))
  m  <- mean(x, na.rm = TRUE)
  s  <- se(x)
  lo <- min(x, na.rm = TRUE)
  hi <- max(x, na.rm = TRUE)
  sprintf("%0.*f ± %0.*f (range %0.*f–%0.*f)",
          digits_mean, m, digits_se, s, digits_range, lo, digits_range, hi)
}

# Ensure numeric columns are clean
map_df$Weight.mg        <- as.numeric(map_df$Weight.mg)
map_df$Wing.Chord.mm    <- as.numeric(map_df$Wing.Chord.mm)
map_df$Right.Tarsus.mm  <- as.numeric(map_df$Right.Tarsus.mm)
map_df$X9th.Primary.mm  <- as.numeric(map_df$X9th.Primary.mm)
map_df$Clutch.Size      <- as.numeric(map_df$Clutch.Size)
map_df$Hatching.Success <- as.numeric(map_df$Hatching.Success)
map_df$Fledging.Success <- as.numeric(map_df$Fledging.Success)
map_df$Box.Temperature  <- as.numeric(map_df$Box.Temperature)

# === Compute BCI (residual mass ~ wing chord) ===
bci_lm <- lm(Weight.mg ~ Wing.Chord.mm, data = map_df, na.action = na.exclude)
map_df$BCI <- resid(bci_lm)

# === Summaries ===
mass     <- summarize_trait(map_df$Weight.mg)
wing     <- summarize_trait(map_df$Wing.Chord.mm)
p9       <- summarize_trait(map_df$X9th.Primary.mm)
tarsus   <- summarize_trait(map_df$Right.Tarsus.mm)
clutch   <- summarize_trait(map_df$Clutch.Size, digits_range = 0)
hatch    <- summarize_trait(map_df$Hatching.Success)
fledge   <- summarize_trait(map_df$Fledging.Success)
bci      <- summarize_trait(map_df$BCI, digits_mean = 2, digits_se = 2, digits_range = 2)
boxtemp  <- summarize_trait(map_df$Box.Temperature)

# === Build manuscript-ready sentence ===
sentence <- paste0(
  "The average body mass of 10-day old tree swallow nestlings was ",
  mass, " g. ",
  "Averages for other morphometrics measured included wing chord length (", wing, " mm), ",
  "9th primary length (", p9, " mm), and right tarsus length (", tarsus, " mm). ",
  "The average clutch size was ", clutch, " eggs, ",
  "with hatching success averaging ", hatch, "% and fledging success averaging ", fledge, "%. ",
  "Residual body-condition index (BCI) was ", bci, ". ",
  "The mean nest box temperature was ", boxtemp, " °C."
)

cat(sentence, "\n")
```

```{r}
## ── One-way ANOVA by Site + Tukey pairwise for ALL morphometrics (fixed) ────
suppressPackageStartupMessages({
  library(dplyr)
  library(multcomp)      # glht(), mcp()
  library(multcompView)  # cld()
})

hdr <- function(x) cat("\n", strrep("=", nchar(x)), "\n", x, "\n", strrep("=", nchar(x)), "\n", sep="")

# 0) Make sure key columns are numeric if present
num_candidates <- c("Weight.mg","Wing.Chord.mm","Right.Tarsus.mm","X9th.Primary.mm",
                    "Clutch.Size","Box.Temperature","Hatching.Success",
                    "Fledging.Success","BCI")
for (cn in intersect(num_candidates, names(map_df))) {
  map_df[[cn]] <- suppressWarnings(as.numeric(map_df[[cn]]))
}

# 1) Detect morphometric variables (numeric) and exclude ID-like columns
id_like <- c("NAME","Site","SampleID","Sample","Nest","NestID","ID")
morpho_vars <- setdiff(names(map_df)[sapply(map_df, is.numeric)], id_like)

hdr("Detected morphometric variables")
print(morpho_vars)

# 2) Loop: ANOVA + Tukey + CLD per variable
for (v in morpho_vars) {
  # Build a small data frame with a constant response name `y`
  dat <- map_df %>%
    dplyr::select(Site, !!rlang::sym(v)) %>%
    dplyr::rename(y = !!rlang::sym(v)) %>%
    dplyr::filter(!is.na(Site), !is.na(y)) %>%
    dplyr::mutate(Site = droplevels(factor(Site)))

  # Need at least 2 site levels and >1 observation total
  if (nlevels(dat$Site) < 2 || nrow(dat) < 2) next

  hdr(paste0("ANOVA + Tukey for: ", v))

  # ANOVA
  aov_fit <- aov(y ~ Site, data = dat)
  cat("\n--- ANOVA table ---\n")
  print(summary(aov_fit))

  # Tukey HSD (base R)
  cat("\n--- Tukey HSD (pairwise) ---\n")
  print(TukeyHSD(aov_fit, which = "Site"))

  # Compact letter display (multcomp)
  cat("\n--- Compact letter display (Tukey groups) ---\n")
  gl <- glht(aov_fit, linfct = mcp(Site = "Tukey"))
  print(cld(gl))
}
```

```{r}
## ── Waste vs Rural tests for ALL morphometrics (t-test w/ safe fallbacks) ───
# Groups
rural_sites <- c("MF","MD")
waste_sites <- c("BRL","BWTP","DWTP","WBS")

# Add Group
map_df$Group <- NA_character_
map_df$Group[map_df$Site %in% rural_sites] <- "Rural"
map_df$Group[map_df$Site %in% waste_sites] <- "Waste"

# Identify numeric morphometrics (keep BCI etc., drop IDs)
id_like <- c("NAME","SampleID","Sample","Nest","NestID","ID","Site","Group")
num_cols <- names(map_df)[vapply(map_df, is.numeric, logical(1))]
morpho_vars <- setdiff(num_cols, id_like)

# Safe coercion (if any numeric columns arrived as character)
for (v in morpho_vars) map_df[[v]] <- suppressWarnings(as.numeric(map_df[[v]]))

safe_test <- function(x, g) {
  keep <- !is.na(x) & !is.na(g) & g %in% c("Rural","Waste")
  x <- x[keep]; g <- g[keep]
  xr <- x[g=="Rural"]; xw <- x[g=="Waste"]
  if (length(xr) < 2 || length(xw) < 2) {
    return(list(method="insufficient_n", p=NA_real_, stat=NA_real_, df=NA_real_, ci=c(NA,NA)))
  }
  vr <- var(xr, na.rm=TRUE); vw <- var(xw, na.rm=TRUE)
  # both groups constant → no variation
  if ((is.na(vr) || vr==0) && (is.na(vw) || vw==0)) {
    return(list(method="no_variation_both_groups", p=NA_real_, stat=NA_real_, df=NA_real_, ci=c(NA,NA)))
  }
  # Try Welch t-test first
  tt <- try(t.test(xr, xw, var.equal=FALSE), silent=TRUE)
  if (!inherits(tt, "try-error")) {
    return(list(method="Welch_t", p=unname(tt$p.value),
                stat=unname(tt$statistic), df=unname(tt$parameter),
                ci=unname(tt$conf.int)))
  }
  # Fallback: Wilcoxon rank-sum (nonparametric)
  wt <- suppressWarnings(wilcox.test(xr, xw, exact=FALSE))
  return(list(method="Wilcoxon_rank_sum", p=unname(wt$p.value),
              stat=NA_real_, df=NA_real_, ci=c(NA,NA)))
}

one_var <- function(v) {
  x <- map_df[[v]]; g <- map_df$Group
  keep <- !is.na(x) & !is.na(g) & g %in% c("Rural","Waste")
  xr <- x[keep & g=="Rural"]; xw <- x[keep & g=="Waste"]
  out <- safe_test(x, g)
  data.frame(
    variable     = v,
    n_rural      = length(xr),
    n_waste      = length(xw),
    mean_rural   = mean(xr, na.rm=TRUE),
    mean_waste   = mean(xw, na.rm=TRUE),
    diff_RminusW = mean(xr, na.rm=TRUE) - mean(xw, na.rm=TRUE),
    test_method  = out$method,
    t_stat       = out$stat,
    df           = out$df,
    p_value      = out$p,
    ci_low       = out$ci[1],
    ci_high      = out$ci[2],
    stringsAsFactors = FALSE
  )
}

res_list <- lapply(morpho_vars, one_var)
t_results <- do.call(rbind, res_list)
t_results <- t_results[order(t_results$p_value), ]

# View all
print(t_results, row.names=FALSE)

# If you want only significant (p<0.05):
# subset(t_results, !is.na(p_value) & p_value < 0.05)
```

```{r}
## ── Site-level table: alpha (Shannon, Simpson), within-site beta (Bray–Curtis) ──
suppressPackageStartupMessages({
  library(phyloseq); library(vegan)
  library(dplyr); library(tidyr); library(tibble); library(stringr)
})

# Choose your phyloseq object (relative abundances help for β)
ps0 <- dat_lessHOST  # or dat_r

# Helper: standard error of the mean
se <- function(x) sd(x, na.rm = TRUE) / sqrt(sum(!is.na(x)))

# 1) Alpha diversity per sample (Shannon, Simpson)
alpha_df <- estimate_richness(ps0, measures = c("Shannon", "Simpson")) %>%
  rownames_to_column("Sample")

meta <- as(sample_data(ps0), "data.frame") %>%
  rownames_to_column("Sample")

alpha_meta <- alpha_df %>%
  left_join(meta, by = "Sample") %>%
  filter(!is.na(Site))

# 2) Per-site alpha stats (mean ± SEM)
alpha_site <- alpha_meta %>%
  group_by(Site) %>%
  summarise(
    n_samples     = n(),
    Shannon_mean  = mean(Shannon, na.rm = TRUE),
    Shannon_SEM   = se(Shannon),
    Simpson_mean  = mean(Simpson, na.rm = TRUE),
    Simpson_SEM   = se(Simpson),
    .groups = "drop"
  )

# 3) Within-site β-diversity (mean pairwise Bray–Curtis among samples in the same site)
#    Use relative abundance to mitigate library size effects
ps_rel <- transform_sample_counts(ps0, function(x) x / sum(x))
X <- as(otu_table(ps_rel), "matrix")
if (taxa_are_rows(ps_rel)) X <- t(X)

# Bray–Curtis on all samples
bc <- vegdist(X, method = "bray")  # this is a 'dist' object in sample order of X

# Map sample names to sites
sam_site <- meta$Site[match(rownames(X), meta$Sample)]
names(sam_site) <- rownames(X)

# function: mean ± SEM of within-site distances
within_site_stats <- function(site_name) {
  sids <- names(sam_site)[sam_site == site_name]
  if (length(sids) < 2) {
    return(tibble(Site = site_name,
                  Beta_within_mean = NA_real_,
                  Beta_within_SEM  = NA_real_))
  }
  # pull the upper-tri distances for this site's samples
  idx <- which(rownames(X) %in% sids)
  subd <- as.matrix(bc)[idx, idx, drop = FALSE]
  # keep upper triangle without diagonal
  dvals <- subd[upper.tri(subd, diag = FALSE)]
  tibble(
    Site = site_name,
    Beta_within_mean = mean(dvals, na.rm = TRUE),
    Beta_within_SEM  = se(dvals)
  )
}

beta_site <- bind_rows(lapply(unique(na.omit(sam_site)), within_site_stats))

# 4) Combine alpha + beta + n into one table
site_table <- alpha_site %>%
  left_join(beta_site, by = "Site") %>%
  arrange(Site) %>%
  # Optional: round for clean display (adjust as you like)
  mutate(
    across(c(Shannon_mean, Shannon_SEM, Simpson_mean, Simpson_SEM,
             Beta_within_mean, Beta_within_SEM), ~round(.x, 3))
  )

cat("\n=== Site-level diversity summary ===\n")
print(site_table)
```

```{r}
## ======================= Firmicutes:Proteobacteria (F:P) tests =======================
## Requirements:
## - phyloseq object `ps`
## - sample_data(ps)$Condition with levels "Rural" and "Waste"
suppressPackageStartupMessages({
  library(phyloseq)
  library(dplyr)
  library(tidyr)
  library(tibble)
  library(stringr)
})

## ---- 0) Checks ---------------------------------------------------------------------
stopifnot(inherits(ps, "phyloseq"))
if (is.null(sample_data(ps, errorIfNULL = FALSE))) stop("ps has no sample_data.")
if (is.null(tax_table(ps,  errorIfNULL = FALSE))) stop("ps has no tax_table.")
if (!"Phylum" %in% colnames(as.data.frame(tax_table(ps)))) stop("No 'Phylum' in tax_table(ps).")
if (is.null(sample_data(ps)$Condition)) stop("sample_data(ps)$Condition is missing.")
# Keep an explicit key for joining
sample_key <- sample_names(ps)

## ---- 1) Phylum agglomeration + relative abundance on full community ----------------
ps_phylum <- tax_glom(ps, taxrank = "Phylum", NArm = TRUE)
ps_rel <- transform_sample_counts(ps_phylum, function(x) if (sum(x) > 0) x / sum(x) else x)

## ---- 2) Standardize phylum names (Firmicutes/Bacillota; Proteobacteria/Pseudomonadota)
tax_df <- as.data.frame(tax_table(ps_rel)) %>%
  mutate(
    Phylum_chr = as.character(Phylum),
    Phylum_std = case_when(
      str_to_lower(Phylum_chr) %in% c("firmicutes","bacillota") ~ "Firmicutes",
      str_to_lower(Phylum_chr) %in% c("proteobacteria","pseudomonadota") ~ "Proteobacteria",
      TRUE ~ Phylum_chr
    )
  ) %>%
  rownames_to_column("OTU")

## ---- 3) Sample-by-phylum (relative abundance), then keep only the two target phyla --
otu_mat <- as(otu_table(ps_rel), "matrix")
if (taxa_are_rows(ps_rel)) otu_mat <- t(otu_mat)

df_long <- as.data.frame(otu_mat) %>%
  rownames_to_column("SampleKey") %>%
  pivot_longer(-SampleKey, names_to = "OTU", values_to = "RA") %>%
  left_join(tax_df[, c("OTU","Phylum_std")], by = "OTU") %>%
  group_by(SampleKey, Phylum_std) %>%
  summarize(RA = sum(RA, na.rm = TRUE), .groups = "drop")

df_wide <- df_long %>%
  filter(Phylum_std %in% c("Firmicutes","Proteobacteria")) %>%
  pivot_wider(names_from = Phylum_std, values_from = RA, values_fill = 0)

## ---- 4) Clean metadata join (force atomic tibble; avoid S4/non-vector cols) --------
meta_df <- sample_data(ps_rel) %>%
  as.data.frame(stringsAsFactors = FALSE) %>%
  rownames_to_column("SampleKey") %>%
  as_tibble(.name_repair = "unique") %>%
  mutate(
    across(everything(), ~ as.vector(.x)),                 # coerce to atomic vectors
    Condition = factor(Condition, levels = c("Rural","Waste"))
  )

dat <- df_wide %>%
  right_join(meta_df, by = "SampleKey") %>%               # keep all samples in metadata
  mutate(
    Firmicutes     = as.numeric(replace_na(Firmicutes, 0)),
    Proteobacteria = as.numeric(replace_na(Proteobacteria, 0))
  )

## ---- 5) Ratios (raw + log, robust to zeros) ---------------------------------------
# Raw ratio: NA if Proteobacteria == 0 to avoid Inf explosions
dat <- dat %>%
  mutate(FP_ratio = ifelse(Proteobacteria > 0, Firmicutes / Proteobacteria, NA_real_))

# Data-driven pseudocount = half of the smallest nonzero across both phyla (fallback 1e-6)
min_F <- suppressWarnings(min(dat$Firmicutes[dat$Firmicutes > 0], na.rm = TRUE))
min_P <- suppressWarnings(min(dat$Proteobacteria[dat$Proteobacteria > 0], na.rm = TRUE))
min_pos <- suppressWarnings(min(min_F, min_P))
pseudo  <- if (is.finite(min_pos)) 0.5 * min_pos else 1e-6

dat <- dat %>%
  mutate(FP_logratio = log((Firmicutes + pseudo) / (Proteobacteria + pseudo)))

## ---- 6) Summaries ------------------------------------------------------------------
summary_ratio <- dat %>%
  select(SampleKey, Condition, Firmicutes, Proteobacteria, FP_ratio, FP_logratio) %>%
  filter(!is.na(Condition)) %>%
  group_by(Condition) %>%
  summarize(
    n               = dplyr::n(),
    mean_ratio      = mean(FP_ratio, na.rm = TRUE),
    sd_ratio        = sd(FP_ratio, na.rm = TRUE),
    median_ratio    = median(FP_ratio, na.rm = TRUE),
    iqr_ratio       = IQR(FP_ratio, na.rm = TRUE),
    mean_logratio   = mean(FP_logratio, na.rm = TRUE),
    sd_logratio     = sd(FP_logratio, na.rm = TRUE),
    median_logratio = median(FP_logratio, na.rm = TRUE),
    iqr_logratio    = IQR(FP_logratio, na.rm = TRUE),
    zeros_F         = sum(Firmicutes == 0, na.rm = TRUE),
    zeros_P         = sum(Proteobacteria == 0, na.rm = TRUE),
    .groups = "drop"
  )

print(summary_ratio)

## ---- 7) Tests (vectors only) -------------------------------------------------------
tt_log <- t.test(FP_logratio ~ Condition, data = dat)                   # primary
wt_raw <- wilcox.test(FP_ratio ~ Condition, data = dat, exact = FALSE)  # secondary

## ---- 8) Compact report lines -------------------------------------------------------
cat("\n--- REPORT ---\n")
cat(sprintf("Welch t-test on F:P log-ratio: t = %.3f, df = %.2f, p = %.4g\n",
            tt_log$statistic, tt_log$parameter, tt_log$p.value))
cat(sprintf("Wilcoxon on F:P raw ratio:    W = %s, p = %.4g\n",
            as.character(wt_raw$statistic), wt_raw$p.value))
cat("\nGroup summaries:\n")
```

```{r}
## ================== F:P ratio by Condition (add-on; does not touch dat) ==================
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
})

# Collapse to Phylum level
ps_phylum <- tax_glom(dat, taxrank = "Phylum")

# Per-sample relative abundances
df_long <- psmelt(ps_phylum) %>%
  group_by(Sample) %>%
  mutate(.tot = sum(Abundance)) %>%
  ungroup() %>%
  mutate(rel = Abundance / .tot)

# Standardize names
df_long <- df_long %>%
  mutate(Phylum_std = case_when(
    Phylum == "Bacillota"      ~ "Firmicutes",
    Phylum == "Pseudomonadota" ~ "Proteobacteria",
    TRUE                       ~ as.character(Phylum)
  ))

# Wide per-sample
df_wide <- df_long %>%
  group_by(Sample, Phylum_std) %>%
  summarise(rel = sum(rel), .groups = "drop") %>%
  pivot_wider(names_from = Phylum_std, values_from = rel, values_fill = 0)

# Metadata
meta <- data.frame(sample_data(dat))
meta$Sample <- rownames(meta)
if (!"Condition" %in% colnames(meta)) {
  meta$Condition <- ifelse(meta$Site %in% c("MF","MD"), "Rural", "Waste")
}
meta$Condition <- factor(meta$Condition, levels = c("Rural","Waste"))

# Join & compute F:P ratio
safe_ratio <- function(num, den, eps = 1e-6) (num + eps) / (den + eps)

fp_df <- meta %>%
  inner_join(df_wide, by = "Sample") %>%
  mutate(
    FP_ratio  = safe_ratio(Firmicutes, Proteobacteria),
    log10_FP  = log10(FP_ratio)
  )

# Group summaries
group_summary <- fp_df %>%
  group_by(Condition) %>%
  summarise(
    n        = n(),
    mean_FP  = mean(FP_ratio),
    sd_FP    = sd(FP_ratio),
    mean_log = mean(log10_FP),
    sd_log   = sd(log10_FP),
    .groups  = "drop"
  )
cat("\n=== Per-group descriptives (F:P) ===\n"); print(group_summary)

# Welch t-test (primary on log10 scale)
tt_log <- t.test(log10_FP ~ Condition, data = fp_df, var.equal = FALSE)
cat("\n=== Welch t-test on log10(F:P) ===\n"); print(tt_log)

# Optional raw ratio t-test
tt_raw <- t.test(FP_ratio ~ Condition, data = fp_df, var.equal = FALSE)
cat("\n=== Welch t-test on raw F:P ratio ===\n"); print(tt_raw)
```
